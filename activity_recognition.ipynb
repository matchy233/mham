{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n\n# Team members (e-mail, legi):\n# chozhang@student.ethz.ch, 22-945-562\n# minghli@student.ethz.ch, 22-953-293\n# changli@student.ethz.ch, 22-944-474\n","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import *\nimport os\nimport sys\ncurr_environ = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\nif curr_environ != 'Localhost':\n    sys.path.append('/kaggle/input/mobile-health-2023-path-detection')\n    input_dir = '/kaggle/input/mobile-health-2023-path-detection'\nelse:\n    input_dir = os.path.abspath('')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:28:49.138382Z","iopub.execute_input":"2023-05-17T12:28:49.139301Z","iopub.status.idle":"2023-05-17T12:28:49.177020Z","shell.execute_reply.started":"2023-05-17T12:28:49.139250Z","shell.execute_reply":"2023-05-17T12:28:49.175827Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# progress bar\nfrom tqdm import tqdm\nfrom time import time\n\n# utilty\nfrom Lilygo.Recording import Recording\nfrom Lilygo.Dataset import Dataset\nfrom os import listdir\nfrom os.path import isfile, join\n\n# plotting\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2023-05-17T12:29:09.553985Z","iopub.execute_input":"2023-05-17T12:29:09.554413Z","iopub.status.idle":"2023-05-17T12:29:09.723739Z","shell.execute_reply.started":"2023-05-17T12:29:09.554381Z","shell.execute_reply":"2023-05-17T12:29:09.722736Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# for signal processing and calculations\nfrom scipy import signal\nfrom scipy.integrate import simpson\nfrom scipy import stats\n\nfrom sklearn import tree\n\n# for tuning parameters\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\n# for skeleton\nfrom sklearn.base import BaseEstimator\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:12.960006Z","iopub.execute_input":"2023-05-17T12:29:12.960471Z","iopub.status.idle":"2023-05-17T12:29:13.960026Z","shell.execute_reply.started":"2023-05-17T12:29:12.960434Z","shell.execute_reply":"2023-05-17T12:29:13.958282Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"### signal processing functions ###\ndef parse(signal, ds_freq: float = 20.0, zero_mean: bool = False):\n    \"\"\"downsampling the signal to specific frequency ds_freq, and make the data\n     with zero mean if zero_mean is True\"\"\"\n    ori_time_seq = np.array(signal.timestamps)\n    ori_value_seq = np.array(signal.values)\n    if zero_mean:\n        ori_value_seq = ori_value_seq - np.mean(ori_value_seq)\n    dt = 1./ds_freq\n    time_seq = np.arange(start=np.min(ori_time_seq),\n                         stop=np.max(ori_time_seq),\n                         step=dt)\n    value_seq = np.interp(time_seq, ori_time_seq, ori_value_seq)\n    return value_seq\n\n\ndef bp_filter(value_seq, fp: float = 3, fs: float = 20.0):\n    \"\"\"apply band pass filter to the sequence. fp is the threshold frequency,\n     and fs is the sampling frequency.\"\"\"\n    sos = signal.butter(N=4, Wn=[0.5, fp],\n                        btype='bandpass', fs=fs, output='sos')\n    filtered = signal.sosfilt(sos, value_seq)\n    return filtered\n\n\ndef get_envelop(value_seq,\n                fs: float = 20,\n                half_window_size: float = 0.5,\n                _min: float = 20.,\n                _max: float = 500.):\n    \"\"\"\n    get the envelop as the adaptive local norm of the signal, currently the mode\n     of vector (no negative values). The envelop is calculated by the maximum in\n     a window, half_window_size is the seconds of time. _min and _max for clip.\n    \"\"\"\n    half_win = int(fs*half_window_size)\n    seq = np.concatenate(\n        [np.zeros((half_win,)), value_seq, np.zeros((half_win,))])\n    envelop = np.array([np.max(seq[k-half_win:k+half_win+1])\n                        for k in range(half_win, half_win+len(value_seq))])\n    return np.clip(envelop, _min, _max)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:14.963958Z","iopub.execute_input":"2023-05-17T12:29:14.964592Z","iopub.status.idle":"2023-05-17T12:29:14.988937Z","shell.execute_reply.started":"2023-05-17T12:29:14.964539Z","shell.execute_reply":"2023-05-17T12:29:14.987069Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Building on prior work [23], raw accelerometer data were converted to signal magnitude vector values ( $SM=\\sqrt{acc^2_x+acc^2_y+acc^2_z}$), thus removing the dependence of the resulting signal from the orientation of the sensor. Mean and standard deviation of the SM were considered jointly with a time-frequency analysis of SM in each 10-s window. The analysis of power spectral density aimed at characterizing the following:\n\n1. The total power in the frequencies between 0.3 Hz and 15 Hz;\n2. The first and second dominant frequencies and their powers in the same frequency band;\n3. The dominant frequency in the 0.6–2.5 Hz band and its power;\n4. The ratio between the power of the first dominant frequency and the total power (0.3–15 Hz);\n5. The ratio between the dominant frequency of the current window and the previous window;\n6. The ratio (R1) between the power at frequencies lower than 3 Hz and the total power (0.3–15 Hz);\n7. The ratio (R2) between the power at frequencies lower than 3 Hz and the total power (0.3–15 Hz);\n8. The ratio (R3) between the power at frequencies in the 1.5–2.5 Hz range and the total power (0.3–15 Hz).","metadata":{}},{"cell_type":"code","source":"def encode_feat_vec(sm):\n    \"\"\" return a list containing feature vectors of all the 10s non-overlapping windows\"\"\"\n    WINDOW = 2000  # 10s window\n    feat_vecs = []\n    df1s = []\n    df2s = []\n    dfb2s = []\n    sf = 50.0\n    for i in range(0, len(sm) - WINDOW, WINDOW):\n        data = sm[i:i+WINDOW]\n        low1 = 0.3\n        high1 = 15\n        low2 = 0.6\n        high2 = 2.5\n        nperseg = 2 / low1 * sf\n        freqs, psd = signal.welch(data, sf, nperseg=nperseg)\n        BAND1 = np.logical_and(freqs >= low1, freqs <= high1)\n        BAND2 = np.logical_and(freqs >= low2, freqs <= high2)\n        freq_res = freqs[1] - freqs[0]\n        # compuate total power\n        total_power = simpson(psd[BAND1], dx=freq_res)\n\n        # compute dominant frequencies for BAND1, BAND2\n        idx_p1 = psd[BAND1].argsort()[-1]\n        df1 = low1 + freq_res * idx_p1\n        pdf1 = simpson(psd[BAND1][idx_p1:idx_p1+2], dx=freq_res)\n        df1s.append(df1)\n\n        idx_p2 = psd[BAND1].argsort()[-2]\n        df2 = low1 + freq_res * idx_p2\n        pdf2 = simpson(psd[BAND1][idx_p2:idx_p2+2], dx=freq_res)\n        df2s.append(df2)\n\n        idx_b2 = psd[BAND2].argsort()[-1]\n        dfb2 = low2 + freq_res * idx_b2\n        pdfb2 = simpson(psd[BAND2][idx_b2:idx_b2+2], dx=freq_res)\n        dfb2s.append(dfb2)\n\n        ratio_pdf1_tot = pdf1 / total_power\n\n        if i != 0:\n            ratio_curr_prev_df1 = df1s[-1] / df1s[-2]\n            ratio_curr_prev_df2 = df2s[-1] / df2s[-2]\n            ratio_curr_prev_dfb2 = dfb2s[-1] / dfb2s[-2]\n        else:\n            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2 = \\\n                1.0, 1.0, 1.0\n\n        R1 = simpson(psd[freqs <= 3], dx=freq_res) / total_power\n        R2 = simpson(psd[freqs > 3], dx=freq_res) / total_power\n\n        feat_vec = [\n            np.mean(data),\n            np.std(data),\n            df1, pdf1, df2, pdf2, dfb2, pdfb2,\n            ratio_pdf1_tot,\n            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2,\n            R1, R2]\n        feat_vecs.append(feat_vec)\n    return feat_vecs\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:29.482878Z","iopub.execute_input":"2023-05-17T12:29:29.484053Z","iopub.status.idle":"2023-05-17T12:29:29.500928Z","shell.execute_reply.started":"2023-05-17T12:29:29.483998Z","shell.execute_reply":"2023-05-17T12:29:29.499449Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def compute_sm(ax, ay, az, normalize=False):\n    sm = np.sqrt(np.sum(np.square([ax, ay, az]), axis=0))\n    if normalize:\n        return sm - np.mean(sm)\n    else:\n        return sm\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:31.897603Z","iopub.execute_input":"2023-05-17T12:29:31.898187Z","iopub.status.idle":"2023-05-17T12:29:31.906735Z","shell.execute_reply.started":"2023-05-17T12:29:31.898137Z","shell.execute_reply":"2023-05-17T12:29:31.905458Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# do not run this often\ntrain_dir = '/kaggle/input/mobile-health-2023-path-detection/data/train/'\nall_train_f = [os.path.join(train_dir, f) for f in os.listdir(train_dir)]\nall_train_f.sort()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:34.155584Z","iopub.execute_input":"2023-05-17T12:29:34.156024Z","iopub.status.idle":"2023-05-17T12:29:34.188357Z","shell.execute_reply.started":"2023-05-17T12:29:34.155993Z","shell.execute_reply":"2023-05-17T12:29:34.187098Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(len(all_train_f))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:35.431964Z","iopub.execute_input":"2023-05-17T12:29:35.432393Z","iopub.status.idle":"2023-05-17T12:29:35.438418Z","shell.execute_reply.started":"2023-05-17T12:29:35.432361Z","shell.execute_reply":"2023-05-17T12:29:35.437112Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"263\n","output_type":"stream"}]},{"cell_type":"code","source":"def parse_accelerometer(trace: Recording, use_zc=True):\n    if use_zc:\n        ax = parse(trace.data['ax'])\n        ay = parse(trace.data['ay'])\n        az = parse(trace.data['az'])\n    else:\n        ax = trace.data['ax'].values\n        ay = trace.data['ay'].values\n        az = trace.data['az'].values\n    return ax, ay, az\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:38.703185Z","iopub.execute_input":"2023-05-17T12:29:38.703673Z","iopub.status.idle":"2023-05-17T12:29:38.711127Z","shell.execute_reply.started":"2023-05-17T12:29:38.703636Z","shell.execute_reply":"2023-05-17T12:29:38.709930Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# do not run this often\nX_train = []\ny_train = []\nX_0 = []\ny_0 = []\nsample_pool = np.random.choice(all_train_f, size=70)\ntest_f = []\nfor f in tqdm(all_train_f):\n    t = Recording(f, no_labels=False, mute=True)\n    if 0 in t.labels['activities']:\n        ax, ay, az = parse_accelerometer(t, use_zc=False)\n        dummy_t = {}\n        dummy_t['ax'] = ax\n        dummy_t['ay'] = ay\n        dummy_t['az'] = az\n        X_0.append(dummy_t)\n        y_0.append(True)\n    elif f in sample_pool:\n        ax, ay, az = parse_accelerometer(t, use_zc=False)\n        dummy_t = {}\n        dummy_t['ax'] = ax\n        dummy_t['ay'] = ay\n        dummy_t['az'] = az\n        X_0.append(dummy_t)\n        y_0.append(False)\n    if len(t.labels['activities']) == 1:\n        ax, ay, az = parse_accelerometer(t, use_zc=False)\n        sm = compute_sm(ax, ay, az, normalize=True)\n        fv = encode_feat_vec(sm)\n        X_train.extend(fv)\n        y_train.extend(t.labels['activities'] * len(fv))\n    else:\n        test_f.append(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# do not run this often\nwith open('/kaggle/working/train.npy', 'wb') as f:\n    np.save(f, np.array(X_train))\n    np.save(f, np.array(y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/activity-recognition-matchy/train.npy', 'rb') as f:\n    X_train = np.load(f)\n    y_train = np.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:29:59.624474Z","iopub.execute_input":"2023-05-17T12:29:59.624974Z","iopub.status.idle":"2023-05-17T12:29:59.647400Z","shell.execute_reply.started":"2023-05-17T12:29:59.624931Z","shell.execute_reply":"2023-05-17T12:29:59.646312Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# d2 = StandStillDetector(std_thresh = 0.17, cont_thresh = 3)\n# d2.score(X_0, y_0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = StandStillDetector()\nparameters = {\n    \"std_thresh\": np.arange(0.15, 0.23, step=0.02),\n    \"cont_thresh\": np.arange(3, 5, step=1)\n}\nparam_tuner = GridSearchCV(d, parameters, cv=5, verbose=3)\nparam_tuner.fit(X_0, y_0)\n\nprint(param_tuner.best_score_)\nprint(param_tuner.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StandStillDetector(BaseEstimator):\n    def __init__(self, mean_thresh = -0.1, std_thresh = 0.1, cont_thresh = 5):\n        # no params, for now\n        self.mean_thresh = mean_thresh\n        self.std_thresh  = std_thresh\n        self.cont_thresh = cont_thresh\n    \n    def fit(self, X, y):\n        # no learning actually\n        return self\n\n    def score(self, X: Sequence[Dict], y, sample_weight=None):\n        from sklearn.metrics import accuracy_score\n        # assume X is traces and y is labels\n        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n\n    def predict_fv(self, feat_vec):\n        clf_as_still = False\n        prev_still = False\n        cont = 0\n        for fv in feat_vec:\n            if fv[1] < self.std_thresh and prev_still == False:\n                prev_still = True\n                cont = 1\n                if cont >= self.cont_thresh:\n                    clf_as_still = True\n                    break\n            elif fv[1] < self.std_thresh and prev_still == True:\n                cont += 1\n                if cont >= self.cont_thresh:\n                    clf_as_still = True\n                    break\n            else:\n                prev_still = False\n                cont = 0\n        return clf_as_still\n\n    def predict(self, traces):\n        # assume array\n        if hasattr(traces, '__len__'):\n            res = np.zeros(len(traces), dtype=int)\n            _traces = traces\n        else:\n            res = np.zeros(1, dtype=int)\n            _traces = [traces]\n        i = 0\n        for trace in _traces:\n            ax, ay, az = trace['ax'], trace['ay'], trace['az']\n            sm = compute_sm(ax, ay, az, normalize=True)\n            feat_vec = encode_feat_vec(sm)\n            clf_as_still = False\n            prev_still = False\n            cont = 0\n            for fv in feat_vec:\n                if fv[1] < self.std_thresh and prev_still == False:\n                    prev_still = True\n                    cont = 1\n                    if cont >= self.cont_thresh:\n                        clf_as_still = True\n                        break\n                elif fv[1] < self.std_thresh and prev_still == True:\n                    cont += 1\n                    if cont >= self.cont_thresh:\n                        clf_as_still = True\n                        break\n                else:\n                    prev_still = False\n                    cont = 0\n            res[i] = clf_as_still\n            i += 1\n        if len(res) == 1:\n            return res[0]\n        else:\n            return res","metadata":{"execution":{"iopub.status.busy":"2023-05-17T13:06:49.132379Z","iopub.execute_input":"2023-05-17T13:06:49.132989Z","iopub.status.idle":"2023-05-17T13:06:49.151187Z","shell.execute_reply.started":"2023-05-17T13:06:49.132939Z","shell.execute_reply":"2023-05-17T13:06:49.149742Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# test in batch\nscores = []\nfor i in tqdm(range(0, len(test_f) + 1 - 20, 20)):\n    batch_f = test_f[i:i+20]\n    traces = [Recording(f, no_labels=False, mute=True) for f in batch_f]\n    labels = [t.labels['board_loc'] for t in traces]\n    scores.append(watchloc_detector.score(traces, labels))\n\nprint(scores)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Activity\n\nActivities contained in the data trace and performed for more than 60 s uninterrupted. \n\nOutput as a list of integers: e.g., `[0, 3]` (`0`: standing still, `1`: walk, `2`: run, `3`: cycle). \n\nThese do not need to be in the right order and they do not need to occur multiple times.","metadata":{}},{"cell_type":"code","source":"class ActivityRecognizer(BaseEstimator):\n    def __init__(self, count_tresh=2):\n        self.clf = tree.DecisionTreeClassifier()\n        self.count_thresh = count_tresh\n\n    def fit(self, X, y): # X is an array of windows\n        selector = np.array([fv[1] > 0.1 for fv in X])\n        _X = X[selector]\n        if isinstance(y, int):\n            _y = [y] * len(_X)\n        else:\n            _y = y[selector]\n        self.clf.fit(_X, _y)\n\n    def score(self, X, y, sample_weight=None):\n        y_predict = self.predict(X)\n        tot_score = 0\n        for true, pred in zip(y, y_predict):\n            # walk 1, run 2, cycle 3\n            # 0.05, 0.05, 0.1\n            true_v = [1 in true, 2 in true, 3 in true]\n            pred_v = [1 in pred, 2 in pred, 3 in pred]\n            score = int(true_v[0] == pred_v[0]) + \\\n                    int(true_v[1] == pred_v[1]) + \\\n                    int(true_v[2] == pred_v[2])\n            score /= 4\n            tot_score += score\n        return tot_score / len(y_predict)\n\n    def predict_fv(self, X):\n        win_res = self.clf.predict(X)\n        values, counts = np.unique(win_res, return_counts=True)\n        return [values[j] \n                for j, count in enumerate(counts) if count >= self.count_thresh]\n\n    def predict(self, traces):\n        # assume array\n        if hasattr(traces, '__len__'):\n            res = [0] * len(traces)\n            _traces = traces\n        else:\n            res = [0]\n            _traces = [traces]\n        i = 0\n        for trace in _traces:\n            if isinstance(trace, Recording):\n                ax, ay, az = parse_accelerometer(trace, use_zc=False)\n                sm = compute_sm(ax, ay, az, normalize=True)\n                feat_vec = encode_feat_vec(sm)\n            else:\n                feat_vec = trace\n            # will get an activity prediction for each window\n            win_res = self.clf.predict(feat_vec) \n            values, counts = np.unique(win_res, return_counts=True)\n            res[i] = [values[j] \n                      for j, count in enumerate(counts) if count >= self.count_thresh]\n            i += 1\n        return res\n#         if len(res) == 1:\n#             return res[0]\n#         else:\n#             return res\n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:50:36.159868Z","iopub.execute_input":"2023-05-17T12:50:36.160304Z","iopub.status.idle":"2023-05-17T12:50:36.179154Z","shell.execute_reply.started":"2023-05-17T12:50:36.160272Z","shell.execute_reply":"2023-05-17T12:50:36.178211Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"act = ActivityRecognizer(count_tresh=2)\nact.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T13:45:55.206912Z","iopub.execute_input":"2023-05-17T13:45:55.207403Z","iopub.status.idle":"2023-05-17T13:45:55.369486Z","shell.execute_reply.started":"2023-05-17T13:45:55.207355Z","shell.execute_reply":"2023-05-17T13:45:55.368271Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/input/activity-recognition-matchy/test_f.pkl', 'rb') as f:\n    test_f = pickle.load(f)\nprint(len(test_f))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:42:22.254754Z","iopub.execute_input":"2023-05-17T12:42:22.255163Z","iopub.status.idle":"2023-05-17T12:42:22.262129Z","shell.execute_reply.started":"2023-05-17T12:42:22.255132Z","shell.execute_reply":"2023-05-17T12:42:22.260873Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"97\n","output_type":"stream"}]},{"cell_type":"code","source":"a_trace = Recording(test_f[0], no_labels=False, mute=True)\nact.score([a_trace], [a_trace.labels['activities']])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:50:40.321609Z","iopub.execute_input":"2023-05-17T12:50:40.322025Z","iopub.status.idle":"2023-05-17T12:50:42.932232Z","shell.execute_reply.started":"2023-05-17T12:50:40.321992Z","shell.execute_reply":"2023-05-17T12:50:42.931069Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.5"},"metadata":{}}]},{"cell_type":"code","source":"# test in batch\nscores = []\nfor i in tqdm(range(0, len(test_f) + 1 - 20, 20)):\n    batch_f = test_f[i:i+20]\n    traces = [Recording(f, no_labels=False, mute=True) for f in batch_f]\n    labels = [t.labels['activities'] for t in traces]\n    scores.append(act.score(traces, labels))\n\nprint(scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T13:41:41.097085Z","iopub.execute_input":"2023-05-17T13:41:41.097540Z","iopub.status.idle":"2023-05-17T13:45:35.006319Z","shell.execute_reply.started":"2023-05-17T13:41:41.097504Z","shell.execute_reply":"2023-05-17T13:45:35.004951Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"\n  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n 25%|██▌       | 1/4 [01:00<03:02, 60.98s/it]\u001b[A\n 50%|█████     | 2/4 [02:03<02:04, 62.10s/it]\u001b[A\n 75%|███████▌  | 3/4 [02:59<00:58, 58.97s/it]\u001b[A\n100%|██████████| 4/4 [03:53<00:00, 58.47s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[0.5875, 0.55, 0.475, 0.525]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.mean(scores))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T13:45:47.310983Z","iopub.execute_input":"2023-05-17T13:45:47.319753Z","iopub.status.idle":"2023-05-17T13:45:47.351400Z","shell.execute_reply.started":"2023-05-17T13:45:47.319305Z","shell.execute_reply":"2023-05-17T13:45:47.343856Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"0.534375\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n\n# Prediction","metadata":{}},{"cell_type":"code","source":"# Get the path of all traces\ndir_traces = '/kaggle/input/mobile-health-2023-path-detection/data/test'\nfilenames = [join(dir_traces, f)\n             for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\nfilenames.sort()\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"is_executing":true,"name":"#%%\n"},"execution":{"iopub.status.busy":"2023-05-17T12:58:13.488097Z","iopub.execute_input":"2023-05-17T12:58:13.488531Z","iopub.status.idle":"2023-05-17T12:58:13.587809Z","shell.execute_reply.started":"2023-05-17T12:58:13.488495Z","shell.execute_reply":"2023-05-17T12:58:13.586552Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# initialize predictors\n# step_counter = StepCounter()\nstand_detector = StandStillDetector(std_thresh=0.17, cont_thresh=3)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T13:06:57.520195Z","iopub.execute_input":"2023-05-17T13:06:57.521213Z","iopub.status.idle":"2023-05-17T13:06:57.526149Z","shell.execute_reply.started":"2023-05-17T13:06:57.521149Z","shell.execute_reply":"2023-05-17T13:06:57.525221Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Loop through all traces and calculate the step count for each trace\nsolution_file = []\nt = []\npbar = tqdm(total=len(filenames), position=0, leave=False)\nfor filename in filenames:\n    trace = Recording(filename, no_labels=True, mute=True)\n    categorization_results = {'watch_loc': 114514, 'path_idx': 114514,\n                              'step_count': 0, 'stand': 0, 'walk': 0, 'run': 0, 'cycle': 0}\n    ax, ay, az = parse_accelerometer(trace)\n    sm = compute_sm(ax, ay, az)\n    fv = encode_feat_vec(\n        compute_sm(*parse_accelerometer(trace, use_zc=False), normalize=True))\n\n    #\n    # Your algorithm goes here\n    # You can access the variable 'watch_loc' in the dictionary 'categorization_results' for example with\n    # categorization_results['watch_loc'] = 1\n    # Make sure, you do not use the gps data and are tolerant for missing data (see task set).\n    # Your program must not crash when single smartphone data traces are missing.\n    #\n    st = time()\n#     categorization_results['watch_loc'] = watchloc_detector.predict_fv(fv)\n#     categorization_results['step_count'] = step_counter.predict(sm)\n    categorization_results['stand'] = int(stand_detector.predict_fv(fv))\n    res = act.predict_fv(fv)\n    if 1 in res:\n        categorization_results['walk'] = 1\n    if 2 in res:\n        categorization_results['run'] = 1\n    if 3 in res:\n        categorization_results['cycle'] = 1\n    et = time()\n    t.append(et - st)\n\n    # Append your calculated results and the id of each trace and category to the solution file\n    trace_id = ''.join([*filename][-8:-5])\n    for counter_label, category in enumerate(categorization_results):\n        solution_file.append(\n            [trace_id + f'_{counter_label+1}', categorization_results[category]])\n    pbar.update(1)\n    pbar.set_description(f'Average infer time: {np.mean(t):.3f}s')\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"is_executing":true,"name":"#%%\n"},"execution":{"iopub.status.busy":"2023-05-17T13:46:02.875305Z","iopub.execute_input":"2023-05-17T13:46:02.875767Z","iopub.status.idle":"2023-05-17T14:08:15.703758Z","shell.execute_reply.started":"2023-05-17T13:46:02.875734Z","shell.execute_reply":"2023-05-17T14:08:15.702528Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"Average infer time: 0.001s: 100%|██████████| 376/376 [22:12<00:00,  2.55s/it]","output_type":"stream"}]},{"cell_type":"code","source":"from joblib import dump, load\ndump(act.clf, '/kaggle/working/activity_recognition.joblib')","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:14:19.300773Z","iopub.execute_input":"2023-05-17T14:14:19.301540Z","iopub.status.idle":"2023-05-17T14:14:19.317618Z","shell.execute_reply.started":"2023-05-17T14:14:19.301489Z","shell.execute_reply":"2023-05-17T14:14:19.316152Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/activity_recognition.joblib']"},"metadata":{}}]},{"cell_type":"code","source":"# Write the detected step counts into a .csv file to then upload the .csv file to Kaggle\n# When cross-checking the .csv file on your computer, we recommend using the text editor and NOT excel so that the results are displayed correctly\n# IMPORTANT: Do NOT change the name of the columns ('Id' and 'Category') of the .csv file\nsubmission_file_df = pd.DataFrame(np.asarray(solution_file), columns=['Id', 'Category'])\nsubmission_file_df.to_csv('/kaggle/working/submission.csv', header=['Id', 'Category'], index=False)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"is_executing":true,"name":"#%%\n"},"execution":{"iopub.status.busy":"2023-05-17T14:08:21.105728Z","iopub.execute_input":"2023-05-17T14:08:21.106459Z","iopub.status.idle":"2023-05-17T14:08:21.128997Z","shell.execute_reply.started":"2023-05-17T14:08:21.106420Z","shell.execute_reply":"2023-05-17T14:08:21.127849Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"submission_file_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T14:08:23.122189Z","iopub.execute_input":"2023-05-17T14:08:23.122634Z","iopub.status.idle":"2023-05-17T14:08:23.135809Z","shell.execute_reply.started":"2023-05-17T14:08:23.122597Z","shell.execute_reply":"2023-05-17T14:08:23.134458Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"      Id Category\n0  001_1   114514\n1  001_2   114514\n2  001_3        0\n3  001_4        0\n4  001_5        1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001_1</td>\n      <td>114514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001_2</td>\n      <td>114514</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001_5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}