{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8e13c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:20.597508Z",
     "iopub.status.busy": "2023-05-14T19:00:20.596853Z",
     "iopub.status.idle": "2023-05-14T19:00:20.603933Z",
     "shell.execute_reply": "2023-05-14T19:00:20.602661Z"
    },
    "papermill": {
     "duration": 0.030574,
     "end_time": "2023-05-14T19:00:20.613534",
     "exception": false,
     "start_time": "2023-05-14T19:00:20.582960",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n",
    "\n",
    "# Team members (e-mail, legi):\n",
    "# chozhang@student.ethz.ch, 22-945-562\n",
    "# minghli@student.ethz.ch, 22-953-293\n",
    "# changli@student.ethz.ch, 22-944-474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67a13de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:20.638045Z",
     "iopub.status.busy": "2023-05-14T19:00:20.637635Z",
     "iopub.status.idle": "2023-05-14T19:00:20.648875Z",
     "shell.execute_reply": "2023-05-14T19:00:20.647855Z"
    },
    "papermill": {
     "duration": 0.028067,
     "end_time": "2023-05-14T19:00:20.652708",
     "exception": false,
     "start_time": "2023-05-14T19:00:20.624641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b4b263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:20.675894Z",
     "iopub.status.busy": "2023-05-14T19:00:20.675003Z",
     "iopub.status.idle": "2023-05-14T19:00:20.680716Z",
     "shell.execute_reply": "2023-05-14T19:00:20.679638Z"
    },
    "papermill": {
     "duration": 0.020526,
     "end_time": "2023-05-14T19:00:20.683520",
     "exception": false,
     "start_time": "2023-05-14T19:00:20.662994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "curr_environ = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n",
    "if curr_environ != 'Localhost': \n",
    "    sys.path.append('/kaggle/input/mobile-health-2023-path-detection')\n",
    "    input_dir = '/kaggle/input/mobile-health-2023-path-detection'\n",
    "else:\n",
    "    input_dir = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c77ffa4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:20.707483Z",
     "iopub.status.busy": "2023-05-14T19:00:20.706840Z",
     "iopub.status.idle": "2023-05-14T19:00:21.303411Z",
     "shell.execute_reply": "2023-05-14T19:00:21.302036Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.613274,
     "end_time": "2023-05-14T19:00:21.307360",
     "exception": false,
     "start_time": "2023-05-14T19:00:20.694086",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Lilygo.Recording import Recording\n",
    "from Lilygo.Dataset import Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287498ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:21.332532Z",
     "iopub.status.busy": "2023-05-14T19:00:21.331063Z",
     "iopub.status.idle": "2023-05-14T19:00:21.338182Z",
     "shell.execute_reply": "2023-05-14T19:00:21.336546Z"
    },
    "papermill": {
     "duration": 0.023548,
     "end_time": "2023-05-14T19:00:21.341683",
     "exception": false,
     "start_time": "2023-05-14T19:00:21.318135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8400e3f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:21.366725Z",
     "iopub.status.busy": "2023-05-14T19:00:21.366025Z",
     "iopub.status.idle": "2023-05-14T19:00:22.878623Z",
     "shell.execute_reply": "2023-05-14T19:00:22.876988Z"
    },
    "papermill": {
     "duration": 1.529282,
     "end_time": "2023-05-14T19:00:22.882142",
     "exception": false,
     "start_time": "2023-05-14T19:00:21.352860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for signal processing and calculations\n",
    "from scipy import signal\n",
    "\n",
    "# for tuning parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9787fdce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:22.906326Z",
     "iopub.status.busy": "2023-05-14T19:00:22.905570Z",
     "iopub.status.idle": "2023-05-14T19:00:22.920185Z",
     "shell.execute_reply": "2023-05-14T19:00:22.919013Z"
    },
    "papermill": {
     "duration": 0.03035,
     "end_time": "2023-05-14T19:00:22.923201",
     "exception": false,
     "start_time": "2023-05-14T19:00:22.892851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### signal processing functions ###\n",
    "def parse(signal, ds_freq:float=20.0, zero_mean:bool=False):\n",
    "    \"\"\"downsampling the signal to specific frequency ds_freq, and make the data\n",
    "     with zero mean if zero_mean is True\"\"\"\n",
    "    ori_time_seq = np.array(signal.timestamps)\n",
    "    ori_value_seq = np.array(signal.values)\n",
    "    if zero_mean: ori_value_seq = ori_value_seq - np.mean(ori_value_seq)\n",
    "    dt = 1./ds_freq\n",
    "    time_seq = np.arange(start=np.min(ori_time_seq), stop=np.max(ori_time_seq), step=dt)\n",
    "    value_seq = np.interp(time_seq, ori_time_seq, ori_value_seq)\n",
    "    return time_seq, value_seq\n",
    "    \n",
    "def bp_filter(value_seq, fp:float=3, fs:float=20.0):\n",
    "    \"\"\"apply band pass filter to the sequence. fp is the threshold frequency,\n",
    "     and fs is the sampling frequency.\"\"\"\n",
    "    sos = signal.butter(N=4, Wn=[0.5,fp], btype='bandpass', fs=fs, output='sos')\n",
    "    filtered = signal.sosfilt(sos, value_seq)\n",
    "    return filtered\n",
    "    \n",
    "def get_envelop(value_seq, \n",
    "                fs:float=20, \n",
    "                half_window_size:float=0.5, \n",
    "                _min:float=20., \n",
    "                _max:float=500.):\n",
    "    \"\"\"\n",
    "    get the envelop as the adaptive local norm of the signal, currently the mode\n",
    "     of vector (no negative values). The envelop is calculated by the maximum in\n",
    "     a window, half_window_size is the seconds of time. _min and _max for clip.\n",
    "    \"\"\"\n",
    "    half_win = int(fs*half_window_size)\n",
    "    seq = np.concatenate([np.zeros((half_win,)),value_seq,np.zeros((half_win,))])\n",
    "    envelop = np.array([np.max(seq[k-half_win:k+half_win+1]) \n",
    "                        for k in range(half_win,half_win+len(value_seq))])\n",
    "    return np.clip(envelop, _min, _max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098e368",
   "metadata": {
    "papermill": {
     "duration": 0.010124,
     "end_time": "2023-05-14T19:00:22.944999",
     "exception": false,
     "start_time": "2023-05-14T19:00:22.934875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tasks\n",
    "\n",
    "## Step Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce22f98e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:22.969626Z",
     "iopub.status.busy": "2023-05-14T19:00:22.968805Z",
     "iopub.status.idle": "2023-05-14T19:00:22.994371Z",
     "shell.execute_reply": "2023-05-14T19:00:22.993273Z"
    },
    "papermill": {
     "duration": 0.042495,
     "end_time": "2023-05-14T19:00:22.998175",
     "exception": false,
     "start_time": "2023-05-14T19:00:22.955680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StepCounter(BaseEstimator):\n",
    "    def __init__(self, acc_min=2.,  acc_max=3., acc_height=0.25,\n",
    "                 gyro_min=20., gyro_max=500., gyro_height=0.5,\n",
    "                 acc_weight=1.0, half_window_size=0.5, width=0.5):\n",
    "        self.acc_min = acc_min\n",
    "        self.acc_max = acc_max\n",
    "        self.acc_height = acc_height\n",
    "        self.gyro_min = gyro_min\n",
    "        self.gyro_max = gyro_max\n",
    "        self.gyro_height = gyro_height\n",
    "        self.acc_weight = acc_weight\n",
    "        self.half_window_size = half_window_size\n",
    "        self.width = width\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        # no learning actually, just to fit the estimator interface\n",
    "        return self\n",
    "\n",
    "    def score(self, X, y_true, sample_weight=None, normalize=True) -> float:\n",
    "        '''\n",
    "        Get the \"score\" of the step counting result. \n",
    "        The score is calculated based on how different the step count is from the true values\n",
    "        '''\n",
    "        y_predicted = self.predict(X)\n",
    "        diff = y_predicted - y_true\n",
    "        scores = np.zeros(len(diff))\n",
    "        for i in range(len(diff)):\n",
    "            s = - abs(diff[i])\n",
    "            scores[i] = s\n",
    "        if normalize:\n",
    "            return np.average(scores, weights=sample_weight)\n",
    "        elif sample_weight is not None:\n",
    "            return np.dot(scores, sample_weight)\n",
    "        else:\n",
    "            return scores.sum()\n",
    "\n",
    "    def predict(self, traces):\n",
    "        # assume array\n",
    "        if hasattr(traces, '__len__'):\n",
    "            res = np.zeros(len(traces), dtype=int)\n",
    "            _traces = traces\n",
    "        else:\n",
    "            res = np.zeros(1, dtype=int)\n",
    "            _traces = [traces]\n",
    "        i = 0\n",
    "        for trace in _traces:\n",
    "            data = trace.data\n",
    "            # accelerator data\n",
    "            ax, ay, az = data['ax'], data['ay'], data['az']\n",
    "            # gyroscope data\n",
    "            gx, gy, gz = data['gx'], data['gy'], data['gz']\n",
    "            acc_step_counts = self._count_steps(ax, ay, az,\n",
    "                                                _max=self.acc_max,\n",
    "                                                _min=self.acc_min,\n",
    "                                                _height=self.acc_height,\n",
    "                                                half_window_size=self.half_window_size,\n",
    "                                                width=self.width)\n",
    "            gyro_step_counts = 0\n",
    "            if self.acc_weight != 1.0:\n",
    "                gyro_step_counts = self._count_steps(gx, gy, gz,\n",
    "                                                    _max=self.gyro_max,\n",
    "                                                    _min=self.gyro_min,\n",
    "                                                    _height=self.gyro_height,\n",
    "                                                    half_window_size=self.half_window_size,\n",
    "                                                    width=self.width)\n",
    "            res[i] = int(self.acc_weight * acc_step_counts +\n",
    "                         (1.0 - self.acc_weight) * gyro_step_counts)\n",
    "            i += 1\n",
    "        if len(res) == 1:\n",
    "            return res[0]\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    def _count_steps(self, ax, ay, az, _max, _min, _height,\n",
    "                     half_window_size=0.5, width=0.5):\n",
    "        # interval of m and temp: 80ms; others 50ms\n",
    "        # acc are in unit \"g\". gyro should be within -255, 255\n",
    "        g_t, gx_v = parse(ax)  # use acceleration seems better.\n",
    "        _, gy_v = parse(ay)\n",
    "        _, gz_v = parse(az)\n",
    "\n",
    "        # calculate the mode.\n",
    "        g_v = np.sqrt(np.sum(np.square([gx_v, gy_v, gz_v]), axis=0))\n",
    "        g_v /= get_envelop(g_v,\n",
    "                           half_window_size=half_window_size,\n",
    "                           _min=_min,\n",
    "                           _max=_max)  # an adaptive local norm\n",
    "        # band pass\n",
    "        filtered_gv = bp_filter(g_v)\n",
    "        # amp 1/4 after filtering, should be amplified 4x.\n",
    "        filtered_gv = filtered_gv * (filtered_gv > 0) * 4\n",
    "\n",
    "        # 0.5 optimal for gyro. not tuned for acc but I am lazy.\n",
    "        peaks, _ = signal.find_peaks(filtered_gv,\n",
    "                                     height=_height,\n",
    "                                     distance=20 * 0.2)\n",
    "        # when _min=20 for acc, height=0.01 looks good. sota: _min=1, height=0.25\n",
    "        step_count = len(peaks)  # peaks are the steps.\n",
    "        return step_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a7560",
   "metadata": {
    "papermill": {
     "duration": 0.010998,
     "end_time": "2023-05-14T19:00:23.020914",
     "exception": false,
     "start_time": "2023-05-14T19:00:23.009916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Smart Watch Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5b6c7",
   "metadata": {
    "papermill": {
     "duration": 0.010892,
     "end_time": "2023-05-14T19:00:23.042845",
     "exception": false,
     "start_time": "2023-05-14T19:00:23.031953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "According to [Kuntze et. al.](https://kaikunze.de/papers/pdf/kunze2005recognizing.pdf) it's sufficient to use a C4.5 decision tree + accelometer to do watch loc detection. (But that paper is very rudimentary)\n",
    "\n",
    "Also [ref1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4510470/), [ref2](https://sophiabano.github.io/allpublications/images/pdfs/PETRA2019.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd4919",
   "metadata": {
    "papermill": {
     "duration": 0.010604,
     "end_time": "2023-05-14T19:00:23.065217",
     "exception": false,
     "start_time": "2023-05-14T19:00:23.054613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Building on prior work [23], raw accelerometer data were converted to signal magnitude vector values ( $SM=\\sqrt{acc^2_x+acc^2_y+acc^2_z}$), thus removing the dependence of the resulting signal from the orientation of the sensor. Mean and standard deviation of the SM were considered jointly with a time-frequency analysis of SM in each 10-s window. The analysis of power spectral density aimed at characterizing the following:\n",
    "\n",
    "1. The total power in the frequencies between 0.3 Hz and 15 Hz;\n",
    "2. The first and second dominant frequencies and their powers in the same frequency band;\n",
    "3. The dominant frequency in the 0.6–2.5 Hz band and its power;\n",
    "4. The ratio between the power of the first dominant frequency and the total power (0.3–15 Hz);\n",
    "5. The ratio between the dominant frequency of the current window and the previous window;\n",
    "6. The ratio (R1) between the power at frequencies lower than 3 Hz and the total power (0.3–15 Hz);\n",
    "7. The ratio (R2) between the power at frequencies lower than 3 Hz and the total power (0.3–15 Hz);\n",
    "8. The ratio (R3) between the power at frequencies in the 1.5–2.5 Hz range and the total power (0.3–15 Hz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea8fb9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:00:23.089684Z",
     "iopub.status.busy": "2023-05-14T19:00:23.089196Z",
     "iopub.status.idle": "2023-05-14T19:01:47.787363Z",
     "shell.execute_reply": "2023-05-14T19:01:47.785817Z"
    },
    "papermill": {
     "duration": 84.714041,
     "end_time": "2023-05-14T19:01:47.790845",
     "exception": false,
     "start_time": "2023-05-14T19:00:23.076804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_pig_traces = '/kaggle/input/mham-task2-submission'\n",
    "pig_traces_fnames = [join(dir_pig_traces, f)\n",
    "                     for f in listdir(dir_pig_traces) if isfile(join(dir_pig_traces, f))]\n",
    "pig_traces_fnames.sort()\n",
    "pig_traces = [Recording(t, no_labels=False, mute=True)\n",
    "              for t in pig_traces_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428932c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:47.816916Z",
     "iopub.status.busy": "2023-05-14T19:01:47.815647Z",
     "iopub.status.idle": "2023-05-14T19:01:47.822954Z",
     "shell.execute_reply": "2023-05-14T19:01:47.821291Z"
    },
    "papermill": {
     "duration": 0.024778,
     "end_time": "2023-05-14T19:01:47.826831",
     "exception": false,
     "start_time": "2023-05-14T19:01:47.802053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import simpson\n",
    "from scipy.fft import rfft, rfftfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0edd009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:47.853353Z",
     "iopub.status.busy": "2023-05-14T19:01:47.852813Z",
     "iopub.status.idle": "2023-05-14T19:01:47.861328Z",
     "shell.execute_reply": "2023-05-14T19:01:47.859490Z"
    },
    "papermill": {
     "duration": 0.026614,
     "end_time": "2023-05-14T19:01:47.865147",
     "exception": false,
     "start_time": "2023-05-14T19:01:47.838533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_trace = pig_traces[0]\n",
    "a_datum = a_trace.data\n",
    "a_label = a_trace.labels\n",
    "ax, ay, az = a_datum['ax'], a_datum['ay'], a_datum['az']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f24227c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:47.888798Z",
     "iopub.status.busy": "2023-05-14T19:01:47.888288Z",
     "iopub.status.idle": "2023-05-14T19:01:47.972944Z",
     "shell.execute_reply": "2023-05-14T19:01:47.970941Z"
    },
    "papermill": {
     "duration": 0.100423,
     "end_time": "2023-05-14T19:01:47.975902",
     "exception": false,
     "start_time": "2023-05-14T19:01:47.875479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130800\n"
     ]
    }
   ],
   "source": [
    "sm = np.sqrt(np.array(ax.values) ** 2 +\n",
    "             np.array(ay.values) ** 2 +\n",
    "             np.array(az.values) ** 2)\n",
    "# normalize sm\n",
    "normalized_sm = sm - np.mean(sm)\n",
    "print(len(sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "641f5632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:47.998851Z",
     "iopub.status.busy": "2023-05-14T19:01:47.998255Z",
     "iopub.status.idle": "2023-05-14T19:01:48.024087Z",
     "shell.execute_reply": "2023-05-14T19:01:48.022456Z"
    },
    "papermill": {
     "duration": 0.041192,
     "end_time": "2023-05-14T19:01:48.027178",
     "exception": false,
     "start_time": "2023-05-14T19:01:47.985986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_feat_vec(sm):\n",
    "    WINDOW = 2000 # 10s window\n",
    "    feat_vecs = []\n",
    "    df1s  = []; df2s  = []; dfb2s = []\n",
    "    sf = 50.0\n",
    "    for i in range(0, len(sm) - WINDOW, WINDOW):\n",
    "        data = sm[i:i+WINDOW]\n",
    "        low1 = 0.3; high1 = 15\n",
    "        low2 = 0.6; high2 = 2.5\n",
    "        nperseg = 2 / low1 * sf\n",
    "        freqs, psd = signal.welch(data, sf, nperseg=nperseg)\n",
    "        BAND1 = np.logical_and(freqs >= low1, freqs <= high1)\n",
    "        BAND2 = np.logical_and(freqs >= low2, freqs <= high2)\n",
    "        freq_res = freqs[1] - freqs[0]\n",
    "        # compuate total power\n",
    "        total_power = simpson(psd[BAND1], dx=freq_res)\n",
    "        \n",
    "        # compute dominant frequencies for BAND1, BAND2\n",
    "        idx_p1 = psd[BAND1].argsort()[-1]\n",
    "        df1 = low1 + freq_res * idx_p1\n",
    "        pdf1  = simpson(psd[BAND1][idx_p1:idx_p1+2], dx=freq_res)\n",
    "        df1s.append(df1)\n",
    "        \n",
    "        idx_p2 = psd[BAND1].argsort()[-2]\n",
    "        df2 = low1 + freq_res * idx_p2\n",
    "        pdf2  = simpson(psd[BAND1][idx_p2:idx_p2+2], dx=freq_res)\n",
    "        df2s.append(df2)\n",
    "        \n",
    "        idx_b2 = psd[BAND2].argsort()[-1]\n",
    "        dfb2 = low2 + freq_res * idx_b2\n",
    "        pdfb2  = simpson(psd[BAND2][idx_b2:idx_b2+2], dx=freq_res)\n",
    "        dfb2s.append(dfb2)\n",
    "        \n",
    "        ratio_pdf1_tot = pdf1 / total_power\n",
    "        \n",
    "        if i != 0:\n",
    "            ratio_curr_prev_df1 = df1s[-1] / df1s[-2]\n",
    "            ratio_curr_prev_df2 = df2s[-1] / df2s[-2]\n",
    "            ratio_curr_prev_dfb2 = dfb2s[-1] / dfb2s[-2]\n",
    "        else:\n",
    "            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2 = \\\n",
    "                1.0, 1.0, 1.0\n",
    "        \n",
    "        R1 = simpson(psd[freqs <= 3], dx=freq_res) / total_power\n",
    "        R2 = simpson(psd[freqs > 3], dx=freq_res) / total_power\n",
    "        \n",
    "        feat_vec = [\n",
    "            np.mean(data), \n",
    "            np.std(data), \n",
    "            df1, pdf1, df2, pdf2, dfb2, pdfb2,\n",
    "            ratio_pdf1_tot,\n",
    "            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2,\n",
    "            R1, R2]\n",
    "        feat_vecs.append(feat_vec)\n",
    "    return feat_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b97c866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:48.049681Z",
     "iopub.status.busy": "2023-05-14T19:01:48.049071Z",
     "iopub.status.idle": "2023-05-14T19:01:48.119728Z",
     "shell.execute_reply": "2023-05-14T19:01:48.118323Z"
    },
    "papermill": {
     "duration": 0.085999,
     "end_time": "2023-05-14T19:01:48.123015",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.037016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_vec = np.asarray(encode_feat_vec(normalized_sm)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d309428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:48.145382Z",
     "iopub.status.busy": "2023-05-14T19:01:48.144149Z",
     "iopub.status.idle": "2023-05-14T19:01:48.152187Z",
     "shell.execute_reply": "2023-05-14T19:01:48.151300Z"
    },
    "papermill": {
     "duration": 0.021674,
     "end_time": "2023-05-14T19:01:48.154823",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.133149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WatchLocPredictor(BaseEstimator):\n",
    "    # required\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def parse(self, data: Recording): # -> list[float]:\n",
    "        _data = data.data\n",
    "        ax, ay, az = _data['ax'], _data['ay'], _data['az']\n",
    "    \n",
    "    # required\n",
    "    def fit(self, data: Recording, labels: list[int]):\n",
    "        # first SVM to classify as walk or non-walk\n",
    "        # second SVM use walk windows to classify location\n",
    "        pass\n",
    "\n",
    "    # required\n",
    "    def predict(self, trace: Recording):\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c17bb",
   "metadata": {
    "papermill": {
     "duration": 0.009367,
     "end_time": "2023-05-14T19:01:48.174316",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.164949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Path Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74728949",
   "metadata": {
    "papermill": {
     "duration": 0.009077,
     "end_time": "2023-05-14T19:01:48.192915",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.183838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "All traces must contain GPS data, so can use this for sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "542011c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:48.213368Z",
     "iopub.status.busy": "2023-05-14T19:01:48.212953Z",
     "iopub.status.idle": "2023-05-14T19:01:48.218856Z",
     "shell.execute_reply": "2023-05-14T19:01:48.217760Z"
    },
    "papermill": {
     "duration": 0.018898,
     "end_time": "2023-05-14T19:01:48.221195",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.202297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PathDetector(BaseEstimator):\n",
    "    # required\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # required\n",
    "    def fit(self, data, labels):\n",
    "        pass\n",
    "\n",
    "    # required\n",
    "    def predict(self, trace):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b30ad",
   "metadata": {
    "papermill": {
     "duration": 0.009368,
     "end_time": "2023-05-14T19:01:48.240373",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.231005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Activity\n",
    "\n",
    "Activities contained in the data trace and performed for more than 60 s uninterrupted. \n",
    "\n",
    "Output as a list of integers: e.g., `[0, 3]` (`0`: standing still, `1`: walk, `2`: run, `3`: cycle). \n",
    "\n",
    "These do not need to be in the right order and they do not need to occur multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f56cf1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:48.262520Z",
     "iopub.status.busy": "2023-05-14T19:01:48.261713Z",
     "iopub.status.idle": "2023-05-14T19:01:48.268543Z",
     "shell.execute_reply": "2023-05-14T19:01:48.267311Z"
    },
    "papermill": {
     "duration": 0.021479,
     "end_time": "2023-05-14T19:01:48.271307",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.249828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ActivityPredictor(BaseEstimator):\n",
    "    # required\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # required\n",
    "    def fit(self, data, labels):\n",
    "        pass\n",
    "\n",
    "    # required\n",
    "    def predict(self, trace):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67385813",
   "metadata": {
    "papermill": {
     "duration": 0.009352,
     "end_time": "2023-05-14T19:01:48.290883",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.281531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d0c863",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:48.315589Z",
     "iopub.status.busy": "2023-05-14T19:01:48.314728Z",
     "iopub.status.idle": "2023-05-14T19:01:48.402940Z",
     "shell.execute_reply": "2023-05-14T19:01:48.401210Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.105681,
     "end_time": "2023-05-14T19:01:48.406161",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.300480",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the path of all traces\n",
    "dir_traces = '/kaggle/input/mobile-health-2023-path-detection/data/test'\n",
    "filenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\n",
    "filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "765238ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:48.430528Z",
     "iopub.status.busy": "2023-05-14T19:01:48.429752Z",
     "iopub.status.idle": "2023-05-14T19:01:48.435146Z",
     "shell.execute_reply": "2023-05-14T19:01:48.434239Z"
    },
    "papermill": {
     "duration": 0.020967,
     "end_time": "2023-05-14T19:01:48.437792",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.416825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize predictors\n",
    "step_counter = StepCounter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75a818d4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-14T19:01:48.459902Z",
     "iopub.status.busy": "2023-05-14T19:01:48.458985Z",
     "iopub.status.idle": "2023-05-14T19:02:27.996565Z",
     "shell.execute_reply": "2023-05-14T19:02:27.995039Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 39.552158,
     "end_time": "2023-05-14T19:02:27.999936",
     "exception": false,
     "start_time": "2023-05-14T19:01:48.447778",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through all traces and calculate the step count for each trace\n",
    "solution_file = []\n",
    "for filename in filenames[:10]:\n",
    "    trace = Recording(filename, no_labels=True, mute=True)\n",
    "    categorization_results = {'watch_loc': 0, 'path_idx': 0, 'step_count': 0, 'stand': 0, 'walk': 0, 'run': 0, 'cycle': 0}\n",
    "\n",
    "    #\n",
    "    # Your algorithm goes here\n",
    "    # You can access the variable 'watch_loc' in the dictionary 'categorization_results' for example with\n",
    "    # categorization_results['watch_loc'] = 1\n",
    "    # Make sure, you do not use the gps data and are tolerant for missing data (see task set).\n",
    "    # Your program must not crash when single smartphone data traces are missing.\n",
    "    #\n",
    "    categorization_results['step_count'] = step_counter.predict(trace)\n",
    "\n",
    "    # Append your calculated results and the id of each trace and category to the solution file\n",
    "    trace_id = ''.join([*filename][-8:-5])\n",
    "    for counter_label, category in enumerate(categorization_results):\n",
    "        solution_file.append([trace_id + f'_{counter_label+1}', categorization_results[category]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d4ec9c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-14T19:02:28.024710Z",
     "iopub.status.busy": "2023-05-14T19:02:28.024188Z",
     "iopub.status.idle": "2023-05-14T19:02:28.049576Z",
     "shell.execute_reply": "2023-05-14T19:02:28.048190Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.041986,
     "end_time": "2023-05-14T19:02:28.052947",
     "exception": false,
     "start_time": "2023-05-14T19:02:28.010961",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write the detected step counts into a .csv file to then upload the .csv file to Kaggle\n",
    "# When cross-checking the .csv file on your computer, we recommend using the text editor and NOT excel so that the results are displayed correctly\n",
    "# IMPORTANT: Do NOT change the name of the columns ('Id' and 'Category') of the .csv file\n",
    "submission_file_df = pd.DataFrame(np.asarray(solution_file), columns=['Id', 'Category'])\n",
    "submission_file_df.to_csv('/kaggle/working/submission.csv', header=['Id', 'Category'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 147.834865,
   "end_time": "2023-05-14T19:02:31.190983",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-14T19:00:03.356118",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
