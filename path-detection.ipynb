{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n\n# Team members (e-mail, legi):\n# chozhang@student.ethz.ch, 22-945-562\n# minghli@student.ethz.ch, 22-953-293\n# changli@student.ethz.ch, 22-944-474","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2023-05-15T19:50:02.935309Z","iopub.execute_input":"2023-05-15T19:50:02.936427Z","iopub.status.idle":"2023-05-15T19:50:02.961070Z","shell.execute_reply.started":"2023-05-15T19:50:02.936353Z","shell.execute_reply":"2023-05-15T19:50:02.959912Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from typing import *\nimport os\nimport sys\ncurr_environ = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\nif curr_environ != 'Localhost': \n    sys.path.append('/kaggle/input/mobile-health-2023-path-detection')\n    input_dir = '/kaggle/input/mobile-health-2023-path-detection'\nelse:\n    input_dir = os.path.abspath('')","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:50:11.642649Z","iopub.execute_input":"2023-05-15T19:50:11.643861Z","iopub.status.idle":"2023-05-15T19:50:11.654401Z","shell.execute_reply.started":"2023-05-15T19:50:11.643804Z","shell.execute_reply":"2023-05-15T19:50:11.653094Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom Lilygo.Recording import Recording\nfrom Lilygo.Dataset import Dataset\nfrom os import listdir\nfrom os.path import isfile, join\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-15T19:50:13.564427Z","iopub.execute_input":"2023-05-15T19:50:13.565515Z","iopub.status.idle":"2023-05-15T19:50:13.690713Z","shell.execute_reply.started":"2023-05-15T19:50:13.565468Z","shell.execute_reply":"2023-05-15T19:50:13.689556Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# for signal processing and calculations\nfrom scipy import signal\n\n# for tuning parameters\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.base import BaseEstimator","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:50:15.556517Z","iopub.execute_input":"2023-05-15T19:50:15.556920Z","iopub.status.idle":"2023-05-15T19:50:16.024453Z","shell.execute_reply.started":"2023-05-15T19:50:15.556889Z","shell.execute_reply":"2023-05-15T19:50:16.023443Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"### signal processing functions ###\ndef parse(signal, ds_freq:float=20.0, zero_mean:bool=False):\n    \"\"\"downsampling the signal to specific frequency ds_freq, and make the data\n     with zero mean if zero_mean is True\"\"\"\n    ori_time_seq = np.array(signal.timestamps)\n    ori_value_seq = np.array(signal.values)\n    if zero_mean: ori_value_seq = ori_value_seq - np.mean(ori_value_seq)\n    dt = 1./ds_freq\n    time_seq = np.arange(start=np.min(ori_time_seq), stop=np.max(ori_time_seq), step=dt)\n    value_seq = np.interp(time_seq, ori_time_seq, ori_value_seq)\n    return time_seq, value_seq\n    \ndef bp_filter(value_seq, fp:float=3, fs:float=20.0):\n    \"\"\"apply band pass filter to the sequence. fp is the threshold frequency,\n     and fs is the sampling frequency.\"\"\"\n    sos = signal.butter(N=4, Wn=[0.5,fp], btype='bandpass', fs=fs, output='sos')\n    filtered = signal.sosfilt(sos, value_seq)\n    return filtered\n    \ndef get_envelop(value_seq, \n                fs:float=20, \n                half_window_size:float=0.5, \n                _min:float=20., \n                _max:float=500.):\n    \"\"\"\n    get the envelop as the adaptive local norm of the signal, currently the mode\n     of vector (no negative values). The envelop is calculated by the maximum in\n     a window, half_window_size is the seconds of time. _min and _max for clip.\n    \"\"\"\n    half_win = int(fs*half_window_size)\n    seq = np.concatenate([np.zeros((half_win,)),value_seq,np.zeros((half_win,))])\n    envelop = np.array([np.max(seq[k-half_win:k+half_win+1]) \n                        for k in range(half_win,half_win+len(value_seq))])\n    return np.clip(envelop, _min, _max)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:50:20.708057Z","iopub.execute_input":"2023-05-15T19:50:20.708472Z","iopub.status.idle":"2023-05-15T19:50:20.718449Z","shell.execute_reply.started":"2023-05-15T19:50:20.708438Z","shell.execute_reply":"2023-05-15T19:50:20.717163Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Tasks\n\n## Step Count","metadata":{}},{"cell_type":"code","source":"class StepCounter(BaseEstimator):\n    def __init__(self, acc_min=2.,  acc_max=3., acc_height=0.25,\n                 gyro_min=20., gyro_max=500., gyro_height=0.5,\n                 acc_weight=1.0, half_window_size=0.5, width=0.5):\n        self.acc_min = acc_min\n        self.acc_max = acc_max\n        self.acc_height = acc_height\n        self.gyro_min = gyro_min\n        self.gyro_max = gyro_max\n        self.gyro_height = gyro_height\n        self.acc_weight = acc_weight\n        self.half_window_size = half_window_size\n        self.width = width\n\n    def fit(self, data, labels):\n        # no learning actually, just to fit the estimator interface\n        return self\n\n    def score(self, X, y_true, sample_weight=None, normalize=True) -> float:\n        '''\n        Get the \"score\" of the step counting result. \n        The score is calculated based on how different the step count is from the true values\n        '''\n        y_predicted = self.predict(X)\n        diff = y_predicted - y_true\n        scores = np.zeros(len(diff))\n        for i in range(len(diff)):\n            s = - abs(diff[i])\n            scores[i] = s\n        if normalize:\n            return np.average(scores, weights=sample_weight)\n        elif sample_weight is not None:\n            return np.dot(scores, sample_weight)\n        else:\n            return scores.sum()\n\n    def predict(self, traces):\n        # assume array\n        if hasattr(traces, '__len__'):\n            res = np.zeros(len(traces), dtype=int)\n            _traces = traces\n        else:\n            res = np.zeros(1, dtype=int)\n            _traces = [traces]\n        i = 0\n        for trace in _traces:\n            data = trace.data\n            # accelerator data\n            ax, ay, az = data['ax'], data['ay'], data['az']\n            # gyroscope data\n            gx, gy, gz = data['gx'], data['gy'], data['gz']\n            acc_step_counts = self._count_steps(ax, ay, az,\n                                                _max=self.acc_max,\n                                                _min=self.acc_min,\n                                                _height=self.acc_height,\n                                                half_window_size=self.half_window_size,\n                                                width=self.width)\n            gyro_step_counts = 0\n            if self.acc_weight != 1.0:\n                gyro_step_counts = self._count_steps(gx, gy, gz,\n                                                    _max=self.gyro_max,\n                                                    _min=self.gyro_min,\n                                                    _height=self.gyro_height,\n                                                    half_window_size=self.half_window_size,\n                                                    width=self.width)\n            res[i] = int(self.acc_weight * acc_step_counts +\n                         (1.0 - self.acc_weight) * gyro_step_counts)\n            i += 1\n        if len(res) == 1:\n            return res[0]\n        else:\n            return res\n\n    def _count_steps(self, ax, ay, az, _max, _min, _height,\n                     half_window_size=0.5, width=0.5):\n        # interval of m and temp: 80ms; others 50ms\n        # acc are in unit \"g\". gyro should be within -255, 255\n        g_t, gx_v = parse(ax)  # use acceleration seems better.\n        _, gy_v = parse(ay)\n        _, gz_v = parse(az)\n\n        # calculate the mode.\n        g_v = np.sqrt(np.sum(np.square([gx_v, gy_v, gz_v]), axis=0))\n        g_v /= get_envelop(g_v,\n                           half_window_size=half_window_size,\n                           _min=_min,\n                           _max=_max)  # an adaptive local norm\n        # band pass\n        filtered_gv = bp_filter(g_v)\n        # amp 1/4 after filtering, should be amplified 4x.\n        filtered_gv = filtered_gv * (filtered_gv > 0) * 4\n\n        # 0.5 optimal for gyro. not tuned for acc but I am lazy.\n        peaks, _ = signal.find_peaks(filtered_gv,\n                                     height=_height,\n                                     distance=20 * 0.2)\n        # when _min=20 for acc, height=0.01 looks good. sota: _min=1, height=0.25\n        step_count = len(peaks)  # peaks are the steps.\n        return step_count\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Smart Watch Location","metadata":{}},{"cell_type":"markdown","source":"According to [Kuntze et. al.](https://kaikunze.de/papers/pdf/kunze2005recognizing.pdf) it's sufficient to use a C4.5 decision tree + accelometer to do watch loc detection. (But that paper is very rudimentary)\n\nAlso [ref1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4510470/), [ref2](https://sophiabano.github.io/allpublications/images/pdfs/PETRA2019.pdf)","metadata":{}},{"cell_type":"markdown","source":"Building on prior work [23], raw accelerometer data were converted to signal magnitude vector values ( $SM=\\sqrt{acc^2_x+acc^2_y+acc^2_z}$), thus removing the dependence of the resulting signal from the orientation of the sensor. Mean and standard deviation of the SM were considered jointly with a time-frequency analysis of SM in each 10-s window. The analysis of power spectral density aimed at characterizing the following:\n\n1. The total power in the frequencies between 0.3 Hz and 15 Hz;\n2. The first and second dominant frequencies and their powers in the same frequency band;\n3. The dominant frequency in the 0.6–2.5 Hz band and its power;\n4. The ratio between the power of the first dominant frequency and the total power (0.3–15 Hz);\n5. The ratio between the dominant frequency of the current window and the previous window;\n6. The ratio (R1) between the power at frequencies lower than 3 Hz and the total power (0.3–15 Hz);\n7. The ratio (R2) between the power at frequencies lower than 3 Hz and the total power (0.3–15 Hz);\n8. The ratio (R3) between the power at frequencies in the 1.5–2.5 Hz range and the total power (0.3–15 Hz).","metadata":{}},{"cell_type":"code","source":"from scipy.integrate import simpson\nfrom scipy.fft import rfft, rfftfreq\nfrom sklearn import svm","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:50:27.266480Z","iopub.execute_input":"2023-05-15T19:50:27.266907Z","iopub.status.idle":"2023-05-15T19:50:27.300856Z","shell.execute_reply.started":"2023-05-15T19:50:27.266874Z","shell.execute_reply":"2023-05-15T19:50:27.299699Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def compute_sm(data: Recording):\n    a_datum = data.data\n    ax, ay, az = a_datum['ax'], a_datum['ay'], a_datum['az']\n    sm = np.sqrt(np.array(ax.values) ** 2 +\n             np.array(ay.values) ** 2 +\n             np.array(az.values) ** 2)\n    # normalize sm\n    normalized_sm = sm - np.mean(sm)\n    return normalized_sm","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:50:38.295594Z","iopub.execute_input":"2023-05-15T19:50:38.296008Z","iopub.status.idle":"2023-05-15T19:50:38.303062Z","shell.execute_reply.started":"2023-05-15T19:50:38.295978Z","shell.execute_reply":"2023-05-15T19:50:38.301796Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def encode_feat_vec(sm):\n    \"\"\" return a list containing feature vectors of all the 10s non-overlapping windows\"\"\"\n    WINDOW = 2000 # 10s window\n    feat_vecs = []\n    df1s  = []; df2s  = []; dfb2s = []\n    sf = 50.0\n    for i in range(0, len(sm) - WINDOW, WINDOW):\n        data = sm[i:i+WINDOW]\n        low1 = 0.3; high1 = 15\n        low2 = 0.6; high2 = 2.5\n        nperseg = 2 / low1 * sf\n        freqs, psd = signal.welch(data, sf, nperseg=nperseg)\n        BAND1 = np.logical_and(freqs >= low1, freqs <= high1)\n        BAND2 = np.logical_and(freqs >= low2, freqs <= high2)\n        freq_res = freqs[1] - freqs[0]\n        # compuate total power\n        total_power = simpson(psd[BAND1], dx=freq_res)\n        \n        # compute dominant frequencies for BAND1, BAND2\n        idx_p1 = psd[BAND1].argsort()[-1]\n        df1 = low1 + freq_res * idx_p1\n        pdf1  = simpson(psd[BAND1][idx_p1:idx_p1+2], dx=freq_res)\n        df1s.append(df1)\n        \n        idx_p2 = psd[BAND1].argsort()[-2]\n        df2 = low1 + freq_res * idx_p2\n        pdf2  = simpson(psd[BAND1][idx_p2:idx_p2+2], dx=freq_res)\n        df2s.append(df2)\n        \n        idx_b2 = psd[BAND2].argsort()[-1]\n        dfb2 = low2 + freq_res * idx_b2\n        pdfb2  = simpson(psd[BAND2][idx_b2:idx_b2+2], dx=freq_res)\n        dfb2s.append(dfb2)\n        \n        ratio_pdf1_tot = pdf1 / total_power\n        \n        if i != 0:\n            ratio_curr_prev_df1 = df1s[-1] / df1s[-2]\n            ratio_curr_prev_df2 = df2s[-1] / df2s[-2]\n            ratio_curr_prev_dfb2 = dfb2s[-1] / dfb2s[-2]\n        else:\n            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2 = \\\n                1.0, 1.0, 1.0\n        \n        R1 = simpson(psd[freqs <= 3], dx=freq_res) / total_power\n        R2 = simpson(psd[freqs > 3], dx=freq_res) / total_power\n        \n        feat_vec = [\n            np.mean(data), \n            np.std(data), \n            df1, pdf1, df2, pdf2, dfb2, pdfb2,\n            ratio_pdf1_tot,\n            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2,\n            R1, R2]\n        feat_vecs.append(feat_vec)\n    return feat_vecs","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:50:40.033272Z","iopub.execute_input":"2023-05-15T19:50:40.033688Z","iopub.status.idle":"2023-05-15T19:50:40.047048Z","shell.execute_reply.started":"2023-05-15T19:50:40.033654Z","shell.execute_reply":"2023-05-15T19:50:40.045808Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def plot_non_walking(trace, window_labels):\n    keys = [['ax', 'ay', 'az']]\n    labels = None\n    fig, ax = plt.subplots(nrows=len(keys),\n                           ncols=1,\n                           figsize=(10, 6),\n                           sharex=True,\n                           squeeze=False)\n    \n    for i, key_group in enumerate(keys):\n        for j, key in enumerate(key_group):\n            label = trace.data[key].title\n            ax[i][0].plot(trace.data[key].timestamps, \n                          trace.data[key].values,\n                          label=label, alpha=.5)\n\n        ax[i][0].legend(loc='lower right')\n        ax[i][0].grid()\n    \n    start = 0\n    end = 0\n    for i in range(len(window_labels)):\n        if window_labels[i] == 0:\n            if start == 0:\n                start = i\n        else:\n            if start != 0:\n                end = i + 1\n#                 ax[0][0].axvspan(start*10, end*10, facecolor='r', alpha=0.5)\n                rect = mpatches.Rectangle((start * 10, -2),\n                                          end * 10 - start * 10,\n                                          4, \n                                          fill=True,\n                                          edgecolor=\"red\",\n                                          linewidth=2,\n                                          facecolor=\"red\")\n                ax[0][0].add_patch(rect)\n                start = 0\n                end = 0\n    # capture last one\n    if start != 0:\n        end = i + 1\n        rect = mpatches.Rectangle((start * 10, -2),\n                                  (end - start) * 10,\n                                  4, \n                                  fill=True,\n                                  edgecolor=\"red\",\n                                  linewidth=2,\n                                  facecolor=\"red\")\n        ax[0][0].add_patch(rect)\n\n    ax[-1][0].set_xlabel('Time[s]')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:50:51.828254Z","iopub.execute_input":"2023-05-15T19:50:51.828715Z","iopub.status.idle":"2023-05-15T19:50:51.840734Z","shell.execute_reply.started":"2023-05-15T19:50:51.828677Z","shell.execute_reply":"2023-05-15T19:50:51.839146Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def compute_windowed_means(sm, win=2000):\n    WINDOW = win # 10s window\n    res = []\n    for i in range(0, len(sm) - WINDOW + 1, WINDOW):\n        data = sm[i:i+WINDOW]\n        res.append(np.mean(data))\n    return np.array(res)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:51:01.390351Z","iopub.execute_input":"2023-05-15T19:51:01.390789Z","iopub.status.idle":"2023-05-15T19:51:01.397352Z","shell.execute_reply.started":"2023-05-15T19:51:01.390755Z","shell.execute_reply":"2023-05-15T19:51:01.396296Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def compute_windowed_std(sm, win=2000):\n    WINDOW = win # 10s window\n    res = []\n    for i in range(0, len(sm) - WINDOW + 1, WINDOW):\n        data = sm[i:i+WINDOW]\n        res.append(np.std(data))\n    return np.array(res)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:51:03.128246Z","iopub.execute_input":"2023-05-15T19:51:03.129418Z","iopub.status.idle":"2023-05-15T19:51:03.135193Z","shell.execute_reply.started":"2023-05-15T19:51:03.129350Z","shell.execute_reply":"2023-05-15T19:51:03.134084Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def label_non_walking(trace):\n    sm = compute_sm(trace)\n    # use mean to mean of 10s window to identify non-walking window\n    means = compute_windowed_std(sm)\n    labels = np.ones(len(means))\n    # mean < 0 -> not walking\n    labels[np.where(means < 0.1)] = 0\n    return labels","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:51:05.002918Z","iopub.execute_input":"2023-05-15T19:51:05.003327Z","iopub.status.idle":"2023-05-15T19:51:05.008276Z","shell.execute_reply.started":"2023-05-15T19:51:05.003294Z","shell.execute_reply":"2023-05-15T19:51:05.007442Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# do not run this often\ntrain_dir = '/kaggle/input/mobile-health-2023-path-detection/data/train/'\nall_train_f = [os.path.join(train_dir, f) for f in os.listdir(train_dir)]\nall_train_f.sort()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:51:09.112914Z","iopub.execute_input":"2023-05-15T19:51:09.113609Z","iopub.status.idle":"2023-05-15T19:51:09.121048Z","shell.execute_reply.started":"2023-05-15T19:51:09.113572Z","shell.execute_reply":"2023-05-15T19:51:09.119884Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# extract training files with 0\ntrain_f_with_0 = []\ntrain_with_0 = []\nfor f in train_f:\n    t = Recording(f, no_labels=False, mute=True)\n    if 0 in t.labels['activities']:\n        train_f_with_0.append(f)\n        train_with_0.append(t)\nprint(len(train_with_0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.kernel_approximation import RBFSampler\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:51:18.173665Z","iopub.execute_input":"2023-05-15T19:51:18.174083Z","iopub.status.idle":"2023-05-15T19:51:18.180135Z","shell.execute_reply.started":"2023-05-15T19:51:18.174051Z","shell.execute_reply":"2023-05-15T19:51:18.179289Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_f, test_f = train_test_split(all_train_f, test_size=0.4,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:50:22.205641Z","iopub.execute_input":"2023-05-15T20:50:22.206118Z","iopub.status.idle":"2023-05-15T20:50:22.212249Z","shell.execute_reply.started":"2023-05-15T20:50:22.206083Z","shell.execute_reply":"2023-05-15T20:50:22.211445Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-15T19:52:49.757959Z","iopub.execute_input":"2023-05-15T19:52:49.758409Z","iopub.status.idle":"2023-05-15T19:52:49.763189Z","shell.execute_reply.started":"2023-05-15T19:52:49.758360Z","shell.execute_reply":"2023-05-15T19:52:49.762053Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"watchloc = WatchLoc()\n\nfor f in tqdm(range(0, len(train_f) + 1 - 20, 20)):\n    batch_f = test_f[i:i+20]\n    t = Recording(f, no_labels=False, mute=True)\n    label = t.labels['board_loc']\n    sm = compute_sm(t)\n    fv = encode_feat_vec(sm)\n    watchloc.partial_fit(fv, label)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:35:32.794399Z","iopub.execute_input":"2023-05-15T20:35:32.794813Z","iopub.status.idle":"2023-05-15T20:38:13.228666Z","shell.execute_reply.started":"2023-05-15T20:35:32.794780Z","shell.execute_reply":"2023-05-15T20:38:13.227100Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"100%|██████████| 52/52 [02:40<00:00,  3.09s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"# test in batch\nfor i in tqdm(range(0, len(test_f) + 1 - 20, 20)):\n    batch_f = test_f[i:i+20]\n    traces = [Recording(f, no_labels=False, mute=True) for f in batch_f]\n    labels = [t.labels['board_loc'] for t in traces]\n    print(watchloc.score(traces, labels))","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:38:19.112937Z","iopub.execute_input":"2023-05-15T20:38:19.114235Z","iopub.status.idle":"2023-05-15T20:48:18.680174Z","shell.execute_reply.started":"2023-05-15T20:38:19.114184Z","shell.execute_reply":"2023-05-15T20:48:18.678974Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":" 10%|█         | 1/10 [00:58<08:50, 58.95s/it]","output_type":"stream"},{"name":"stdout","text":"0.15\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [01:56<07:45, 58.16s/it]","output_type":"stream"},{"name":"stdout","text":"0.4\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [02:59<07:02, 60.39s/it]","output_type":"stream"},{"name":"stdout","text":"0.45\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [03:58<05:58, 59.69s/it]","output_type":"stream"},{"name":"stdout","text":"0.25\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [04:53<04:50, 58.10s/it]","output_type":"stream"},{"name":"stdout","text":"0.4\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [05:58<04:02, 60.58s/it]","output_type":"stream"},{"name":"stdout","text":"0.45\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [06:55<02:57, 59.25s/it]","output_type":"stream"},{"name":"stdout","text":"0.35\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [07:59<02:01, 60.84s/it]","output_type":"stream"},{"name":"stdout","text":"0.45\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [08:57<01:00, 60.04s/it]","output_type":"stream"},{"name":"stdout","text":"0.25\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [09:59<00:00, 59.96s/it]","output_type":"stream"},{"name":"stdout","text":"0.4\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"watchloc.predict(traces)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:48:18.692864Z","iopub.execute_input":"2023-05-15T20:48:18.693311Z","iopub.status.idle":"2023-05-15T20:48:20.342453Z","shell.execute_reply.started":"2023-05-15T20:48:18.693262Z","shell.execute_reply":"2023-05-15T20:48:20.341229Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"},"metadata":{}}]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:48:18.682867Z","iopub.execute_input":"2023-05-15T20:48:18.683915Z","iopub.status.idle":"2023-05-15T20:48:18.691002Z","shell.execute_reply.started":"2023-05-15T20:48:18.683867Z","shell.execute_reply":"2023-05-15T20:48:18.689670Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"[0, 2, 0, 2, 1, 2, 1, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 2, 2, 2]"},"metadata":{}}]},{"cell_type":"code","source":"test.labels['board_loc']","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:17:29.983151Z","iopub.execute_input":"2023-05-15T20:17:29.983916Z","iopub.status.idle":"2023-05-15T20:17:29.990268Z","shell.execute_reply.started":"2023-05-15T20:17:29.983877Z","shell.execute_reply":"2023-05-15T20:17:29.989450Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"from scipy import stats","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:54.729175Z","iopub.execute_input":"2023-05-15T20:10:54.729671Z","iopub.status.idle":"2023-05-15T20:10:54.734920Z","shell.execute_reply.started":"2023-05-15T20:10:54.729633Z","shell.execute_reply":"2023-05-15T20:10:54.733988Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class WatchLoc(BaseEstimator):\n    # required\n    def __init__(self, C=4, gamma=0.25):\n        self.rbf = RBFSampler(gamma=gamma, random_state=1)\n        self.clf = SGDClassifier(alpha=C, max_iter=5)\n    \n    # required\n    def fit(self, data, labels):\n        # remove feature with std (fv[1]) < 0.1\n        _data = [ fv for fv in data if fv[1] > 0.1 ]\n        X_features = self.rbf.fit_transform(_data)\n        self.clf.fit(X_features, labels)\n        return self\n    \n    def score(self, X, y, sample_weight=None):\n        from sklearn.metrics import accuracy_score\n        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n    \n    def partial_fit(self, data, labels, classes=[0, 1, 2]):\n        # remove feature with std (fv[1]) < 0.1\n        _data = [ fv for fv in data if fv[1] > 0.1 ]\n        if isinstance(labels, int):\n            labels = [labels] * len(_data)\n        X_features = self.rbf.fit_transform(_data)\n        self.clf.partial_fit(X_features, labels, classes=classes)\n        return self\n\n    # required\n    def predict(self, traces):\n        # assume array\n        if hasattr(traces, '__len__'):\n            res = np.zeros(len(traces), dtype=int)\n            _traces = traces\n        else:\n            res = np.zeros(1, dtype=int)\n            _traces = [traces]\n        i = 0\n        for trace in _traces:\n            sm = compute_sm(trace)\n            feat_vec = encode_feat_vec(sm)\n            feat_transformed = self.rbf.fit_transform(feat_vec)\n            win_res = self.clf.predict(feat_transformed)\n            res[i] = stats.mode(win_res).mode[0]\n            i += 1\n        if len(res) == 1:\n            return res[0]\n        else:\n            return res\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:18:45.668892Z","iopub.execute_input":"2023-05-15T20:18:45.669309Z","iopub.status.idle":"2023-05-15T20:18:45.682330Z","shell.execute_reply.started":"2023-05-15T20:18:45.669277Z","shell.execute_reply":"2023-05-15T20:18:45.681024Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print (stats.mode([1, 1, 2, 3, 5]).mode[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:13:16.997780Z","iopub.execute_input":"2023-05-15T20:13:16.998222Z","iopub.status.idle":"2023-05-15T20:13:17.004161Z","shell.execute_reply.started":"2023-05-15T20:13:16.998188Z","shell.execute_reply":"2023-05-15T20:13:17.003261Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n\n## Path Index","metadata":{}},{"cell_type":"markdown","source":"All traces must contain GPS data, so can use this for sanity check.","metadata":{}},{"cell_type":"code","source":"class PathDetector(BaseEstimator):\n    # required\n    def __init__(self):\n        pass\n\n    # required\n    def fit(self, data, labels):\n        pass\n\n    # required\n    def predict(self, trace):\n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Activity\n\nActivities contained in the data trace and performed for more than 60 s uninterrupted. \n\nOutput as a list of integers: e.g., `[0, 3]` (`0`: standing still, `1`: walk, `2`: run, `3`: cycle). \n\nThese do not need to be in the right order and they do not need to occur multiple times.","metadata":{}},{"cell_type":"code","source":"class ActivityPredictor(BaseEstimator):\n    # required\n    def __init__(self):\n        pass\n\n    # required\n    def fit(self, data, labels):\n        pass\n\n    # required\n    def predict(self, trace):\n        pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Prediction","metadata":{}},{"cell_type":"code","source":"# Get the path of all traces\ndir_traces = '/kaggle/input/mobile-health-2023-path-detection/data/test'\nfilenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\nfilenames.sort()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n","is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-15T20:34:33.203084Z","iopub.execute_input":"2023-05-15T20:34:33.203566Z","iopub.status.idle":"2023-05-15T20:34:33.301073Z","shell.execute_reply.started":"2023-05-15T20:34:33.203523Z","shell.execute_reply":"2023-05-15T20:34:33.299824Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# initialize predictors\nstep_counter = StepCounter()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through all traces and calculate the step count for each trace\nsolution_file = []\nfor filename in tqdm(filenames):\n    trace = Recording(filename, no_labels=True, mute=True)\n    categorization_results = {'watch_loc': 0, 'path_idx': 114, 'step_count': 514, 'stand': 19, 'walk': 19, 'run': 8, 'cycle': 10}\n\n    #\n    # Your algorithm goes here\n    # You can access the variable 'watch_loc' in the dictionary 'categorization_results' for example with\n    # categorization_results['watch_loc'] = 1\n    # Make sure, you do not use the gps data and are tolerant for missing data (see task set).\n    # Your program must not crash when single smartphone data traces are missing.\n    #\n    categorization_results['watch_loc'] = watchloc.predict(trace)\n\n    # Append your calculated results and the id of each trace and category to the solution file\n    trace_id = ''.join([*filename][-8:-5])\n    for counter_label, category in enumerate(categorization_results):\n        solution_file.append([trace_id + f'_{counter_label+1}', categorization_results[category]])\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n","is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-15T20:34:47.676306Z","iopub.execute_input":"2023-05-15T20:34:47.676777Z","iopub.status.idle":"2023-05-15T20:35:05.419135Z","shell.execute_reply.started":"2023-05-15T20:34:47.676740Z","shell.execute_reply":"2023-05-15T20:35:05.417460Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"  1%|          | 4/376 [00:17<27:15,  4.40s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[67], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m solution_file \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m tqdm(filenames):\n\u001b[0;32m----> 4\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43mRecording\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     categorization_results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatch_loc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_idx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m114\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_count\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m514\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m19\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwalk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m19\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcycle\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m}\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Your algorithm goes here\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# You can access the variable 'watch_loc' in the dictionary 'categorization_results' for example with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Your program must not crash when single smartphone data traces are missing.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n","File \u001b[0;32m/kaggle/input/mobile-health-2023-path-detection/Lilygo/Recording.py:73\u001b[0m, in \u001b[0;36mRecording.__init__\u001b[0;34m(self, filename, no_labels, mute)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Will hold a dictionary directly read from the JSON file\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetAllData()\n","File \u001b[0;32m/kaggle/input/mobile-health-2023-path-detection/Lilygo/Recording.py:109\u001b[0m, in \u001b[0;36mRecording.readFile\u001b[0;34m(self, filename, no_labels, mute)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_str[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m file_str[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    108\u001b[0m         file_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_str\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Write the detected step counts into a .csv file to then upload the .csv file to Kaggle\n# When cross-checking the .csv file on your computer, we recommend using the text editor and NOT excel so that the results are displayed correctly\n# IMPORTANT: Do NOT change the name of the columns ('Id' and 'Category') of the .csv file\nsubmission_file_df = pd.DataFrame(np.asarray(solution_file), columns=['Id', 'Category'])\nsubmission_file_df.to_csv('/kaggle/working/submission.csv', header=['Id', 'Category'], index=False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n","is_executing":true},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_file_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}