{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n",
    "\n",
    "# Team members (e-mail, legi):\n",
    "# chozhang@student.ethz.ch, 22-945-562\n",
    "# minghli@student.ethz.ch, 22-953-293\n",
    "# changli@student.ethz.ch, 22-944-474\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import os\n",
    "import sys\n",
    "curr_environ = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n",
    "if curr_environ != 'Localhost':\n",
    "    sys.path.append('/kaggle/input/mobile-health-2023-path-detection')\n",
    "    input_dir = '/kaggle/input/mobile-health-2023-path-detection'\n",
    "else:\n",
    "    input_dir = os.path.abspath('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Lilygo.Recording import Recording\n",
    "from Lilygo.Dataset import Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress bar\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# for signal processing and calculations\n",
    "from scipy import signal\n",
    "from scipy.integrate import simpson\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# load models\n",
    "from joblib import load\n",
    "\n",
    "# for tuning parameters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for skeleton\n",
    "from sklearn.base import BaseEstimator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### signal processing functions ###\n",
    "def parse(signal, ds_freq: float = 20.0, zero_mean: bool = False):\n",
    "    \"\"\"downsampling the signal to specific frequency ds_freq, and make the data\n",
    "     with zero mean if zero_mean is True\"\"\"\n",
    "    ori_time_seq = np.array(signal.timestamps)\n",
    "    ori_value_seq = np.array(signal.values)\n",
    "    if zero_mean:\n",
    "        ori_value_seq = ori_value_seq - np.mean(ori_value_seq)\n",
    "    dt = 1./ds_freq\n",
    "    time_seq = np.arange(start=np.min(ori_time_seq),\n",
    "                         stop=np.max(ori_time_seq),\n",
    "                         step=dt)\n",
    "    value_seq = np.interp(time_seq, ori_time_seq, ori_value_seq)\n",
    "    return value_seq\n",
    "\n",
    "\n",
    "def bp_filter(value_seq, fp: float = 3, fs: float = 20.0):\n",
    "    \"\"\"apply band pass filter to the sequence. fp is the threshold frequency,\n",
    "     and fs is the sampling frequency.\"\"\"\n",
    "    sos = signal.butter(N=4, Wn=[0.5, fp],\n",
    "                        btype='bandpass', fs=fs, output='sos')\n",
    "    filtered = signal.sosfilt(sos, value_seq)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def get_envelop(value_seq,\n",
    "                fs: float = 20,\n",
    "                half_window_size: float = 0.5,\n",
    "                _min: float = 20.,\n",
    "                _max: float = 500.):\n",
    "    \"\"\"\n",
    "    get the envelop as the adaptive local norm of the signal, currently the mode\n",
    "     of vector (no negative values). The envelop is calculated by the maximum in\n",
    "     a window, half_window_size is the seconds of time. _min and _max for clip.\n",
    "    \"\"\"\n",
    "    half_win = int(fs*half_window_size)\n",
    "    seq = np.concatenate(\n",
    "        [np.zeros((half_win,)), value_seq, np.zeros((half_win,))])\n",
    "    envelop = np.array([np.max(seq[k-half_win:k+half_win+1])\n",
    "                        for k in range(half_win, half_win+len(value_seq))])\n",
    "    return np.clip(envelop, _min, _max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sm(ax, ay, az, normalize=False):\n",
    "    sm = np.sqrt(np.sum(np.square([ax, ay, az]), axis=0))\n",
    "    if normalize:\n",
    "        return sm - np.mean(sm)\n",
    "    else:\n",
    "        return sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_accelerometer(trace: Recording, use_zc=True):\n",
    "    if use_zc:\n",
    "        ax = parse(trace.data['ax'])\n",
    "        ay = parse(trace.data['ay'])\n",
    "        az = parse(trace.data['az'])\n",
    "    else:\n",
    "        ax = trace.data['ax']\n",
    "        ay = trace.data['ay']\n",
    "        az = trace.data['az']\n",
    "    return ax, ay, az\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepCounter(BaseEstimator):\n",
    "    def __init__(self, acc_min=2.,  acc_max=3., acc_height=0.25,\n",
    "                 half_window_size=0.5, width=0.5):\n",
    "        self.acc_min = acc_min\n",
    "        self.acc_max = acc_max\n",
    "        self.acc_height = acc_height\n",
    "        self.half_window_size = half_window_size\n",
    "        self.width = width\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        # no learning actually, just to fit the estimator interface\n",
    "        return self\n",
    "\n",
    "    def score(self, X, y_true, sample_weight=None, normalize=True) -> float:\n",
    "        '''\n",
    "        Get the \"score\" of the step counting result. \n",
    "        The score is calculated based on how different the step count is from the true values\n",
    "        '''\n",
    "        y_predicted = self.predict(X)\n",
    "        diff = y_predicted - y_true\n",
    "        scores = np.zeros(len(diff))\n",
    "        for i in range(len(diff)):\n",
    "            s = - abs(diff[i])\n",
    "            scores[i] = s\n",
    "        if normalize:\n",
    "            return np.average(scores, weights=sample_weight)\n",
    "        elif sample_weight is not None:\n",
    "            return np.dot(scores, sample_weight)\n",
    "        else:\n",
    "            return scores.sum()\n",
    "\n",
    "    def predict(self, sm):\n",
    "        acc_step_counts = self._count_steps(sm,\n",
    "                                            _max=self.acc_max,\n",
    "                                            _min=self.acc_min,\n",
    "                                            _height=self.acc_height,\n",
    "                                            half_window_size=self.half_window_size,\n",
    "                                            width=self.width)\n",
    "        res = int(acc_step_counts)\n",
    "        return res\n",
    "\n",
    "    def _count_steps(self, sm, _max, _min, _height,\n",
    "                     half_window_size=0.5, width=0.5):\n",
    "\n",
    "        # calculate the mode.\n",
    "        g_v = sm\n",
    "        g_v /= get_envelop(g_v,\n",
    "                           half_window_size=half_window_size,\n",
    "                           _min=_min,\n",
    "                           _max=_max)  # an adaptive local norm\n",
    "        # band pass\n",
    "        filtered_gv = bp_filter(g_v)\n",
    "        # amp 1/4 after filtering, should be amplified 4x.\n",
    "        filtered_gv = filtered_gv * (filtered_gv > 0) * 4\n",
    "\n",
    "        # 0.5 optimal for gyro. not tuned for acc but I am lazy.\n",
    "        peaks, _ = signal.find_peaks(filtered_gv,\n",
    "                                     height=_height,\n",
    "                                     distance=20 * 0.2)\n",
    "        # when _min=20 for acc, height=0.01 looks good. sota: _min=1, height=0.25\n",
    "        step_count = len(peaks)  # peaks are the steps.\n",
    "        return step_count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Watch Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feat_vec(sm):\n",
    "    \"\"\" return a list containing feature vectors of all the 10s non-overlapping windows\"\"\"\n",
    "    WINDOW = 2000  # 10s window\n",
    "    feat_vecs = []\n",
    "    df1s = []\n",
    "    df2s = []\n",
    "    dfb2s = []\n",
    "    sf = 50.0\n",
    "    for i in range(0, len(sm) - WINDOW, WINDOW):\n",
    "        data = sm[i:i+WINDOW]\n",
    "        low1 = 0.3\n",
    "        high1 = 15\n",
    "        low2 = 0.6\n",
    "        high2 = 2.5\n",
    "        nperseg = 2 / low1 * sf\n",
    "        freqs, psd = signal.welch(data, sf, nperseg=nperseg)\n",
    "        BAND1 = np.logical_and(freqs >= low1, freqs <= high1)\n",
    "        BAND2 = np.logical_and(freqs >= low2, freqs <= high2)\n",
    "        freq_res = freqs[1] - freqs[0]\n",
    "        # compuate total power\n",
    "        total_power = simpson(psd[BAND1], dx=freq_res)\n",
    "\n",
    "        # compute dominant frequencies for BAND1, BAND2\n",
    "        idx_p1 = psd[BAND1].argsort()[-1]\n",
    "        df1 = low1 + freq_res * idx_p1\n",
    "        pdf1 = simpson(psd[BAND1][idx_p1:idx_p1+2], dx=freq_res)\n",
    "        df1s.append(df1)\n",
    "\n",
    "        idx_p2 = psd[BAND1].argsort()[-2]\n",
    "        df2 = low1 + freq_res * idx_p2\n",
    "        pdf2 = simpson(psd[BAND1][idx_p2:idx_p2+2], dx=freq_res)\n",
    "        df2s.append(df2)\n",
    "\n",
    "        idx_b2 = psd[BAND2].argsort()[-1]\n",
    "        dfb2 = low2 + freq_res * idx_b2\n",
    "        pdfb2 = simpson(psd[BAND2][idx_b2:idx_b2+2], dx=freq_res)\n",
    "        dfb2s.append(dfb2)\n",
    "\n",
    "        ratio_pdf1_tot = pdf1 / total_power\n",
    "\n",
    "        if i != 0:\n",
    "            ratio_curr_prev_df1 = df1s[-1] / df1s[-2]\n",
    "            ratio_curr_prev_df2 = df2s[-1] / df2s[-2]\n",
    "            ratio_curr_prev_dfb2 = dfb2s[-1] / dfb2s[-2]\n",
    "        else:\n",
    "            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2 = \\\n",
    "                1.0, 1.0, 1.0\n",
    "\n",
    "        R1 = simpson(psd[freqs <= 3], dx=freq_res) / total_power\n",
    "        R2 = simpson(psd[freqs > 3], dx=freq_res) / total_power\n",
    "\n",
    "        feat_vec = [\n",
    "            np.mean(data),\n",
    "            np.std(data),\n",
    "            df1, pdf1, df2, pdf2, dfb2, pdfb2,\n",
    "            ratio_pdf1_tot,\n",
    "            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2,\n",
    "            R1, R2]\n",
    "        feat_vecs.append(feat_vec)\n",
    "    return feat_vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree version\n",
    "class WatchLocDetector(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        selector = np.array([fv[1] > 0.1 for fv in X])\n",
    "        _X = X[selector]\n",
    "        if isinstance(y, int):\n",
    "            _y = [y] * len(_data)\n",
    "        else:\n",
    "            _y = y[selector]\n",
    "        self.clf.fit(_X, _y)\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
    "\n",
    "    def predict_fv(self, X):\n",
    "        win_res = self.clf.predict(X)\n",
    "        return stats.mode(win_res).mode[0]\n",
    "\n",
    "    def predict(self, traces):\n",
    "        # assume array\n",
    "        if hasattr(traces, '__len__'):\n",
    "            res = np.zeros(len(traces), dtype=int)\n",
    "            _traces = traces\n",
    "        else:\n",
    "            res = np.zeros(1, dtype=int)\n",
    "            _traces = [traces]\n",
    "        i = 0\n",
    "        for trace in _traces:\n",
    "            if isinstance(trace, Recording):\n",
    "                ax, ay, az = parse_accelerometer(trace)\n",
    "                sm = compute_sm(ax, ay, az, normalize=True)\n",
    "                feat_vec = encode_feat_vec(sm)\n",
    "            else:\n",
    "                feat_vec = trace\n",
    "            win_res = self.clf.predict(feat_vec)\n",
    "            res[i] = stats.mode(win_res).mode[0]\n",
    "            i += 1\n",
    "        if len(res) == 1:\n",
    "            return res[0]\n",
    "        else:\n",
    "            return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the path of all traces\n",
    "dir_traces = '/kaggle/input/mobile-health-2023-path-detection/data/test'\n",
    "filenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\n",
    "filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_counter = StepCounter()\n",
    "watchloc_detector = WatchLocDetector()\n",
    "watchloc_detector.clf = load('/kaggle/working/watchloc_detector.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through all traces and calculate the step count for each trace\n",
    "solution_file = []\n",
    "for filename in filenames:\n",
    "    trace = Recording(filename, no_labels=True, mute=True)\n",
    "    categorization_results = {'watch_loc': 0, 'path_idx': 0,\n",
    "                              'step_count': 0, 'stand': 0, 'walk': 0, 'run': 0, 'cycle': 0}\n",
    "    ax, ay, az = parse_accelerometer(trace)\n",
    "    sm = compute_sm(ax, ay, az)\n",
    "    fv = encode_feat_vec(compute_sm(\n",
    "        parse_accelerometer(trace, use_zc=False), normalize=True))\n",
    "\n",
    "    #\n",
    "    # Your algorithm goes here\n",
    "    # You can access the variable 'watch_loc' in the dictionary 'categorization_results' for example with\n",
    "    # categorization_results['watch_loc'] = 1\n",
    "    # Make sure, you do not use the gps data and are tolerant for missing data (see task set).\n",
    "    # Your program must not crash when single smartphone data traces are missing.\n",
    "    #\n",
    "    categorization_results['watch_loc'] = watchloc_detector.predict_fv(fv)\n",
    "    categorization_results['step_count'] = step_counter.predict(sm)\n",
    "\n",
    "    # Append your calculated results and the id of each trace and category to the solution file\n",
    "    trace_id = ''.join([*filename][-8:-5])\n",
    "    for counter_label, category in enumerate(categorization_results):\n",
    "        solution_file.append(\n",
    "            [trace_id + f'_{counter_label+1}', categorization_results[category]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write the detected step counts into a .csv file to then upload the .csv file to Kaggle\n",
    "# When cross-checking the .csv file on your computer, we recommend using the text editor and NOT excel so that the results are displayed correctly\n",
    "# IMPORTANT: Do NOT change the name of the columns ('Id' and 'Category') of the .csv file\n",
    "submission_file_df = pd.DataFrame(np.asarray(solution_file), columns=['Id', 'Category'])\n",
    "submission_file_df.to_csv('/kaggle/working/submission.csv', header=['Id', 'Category'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
