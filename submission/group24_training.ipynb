{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n",
    "\n",
    "# Team members (e-mail, legi):\n",
    "# chozhang@student.ethz.ch, 22-945-562\n",
    "# minghli@student.ethz.ch, 22-953-293\n",
    "# changli@student.ethz.ch, 22-944-474\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import os\n",
    "import sys\n",
    "curr_environ = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n",
    "if curr_environ != 'Localhost':\n",
    "    sys.path.append('/kaggle/input/mobile-health-2023-path-detection')\n",
    "    input_dir = '/kaggle/input/mobile-health-2023-path-detection'\n",
    "else:\n",
    "    input_dir = os.path.abspath('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "# utilty\n",
    "from Lilygo.Recording import Recording\n",
    "from Lilygo.Dataset import Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for signal processing and calculations\n",
    "from scipy import signal\n",
    "from scipy.integrate import simpson\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# dump and load model\n",
    "from joblib import dump, load\n",
    "\n",
    "# for tuning parameters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for skeleton\n",
    "from sklearn.base import BaseEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### signal processing functions ###\n",
    "def parse(signal, ds_freq: float = 20.0, zero_mean: bool = False):\n",
    "    \"\"\"downsampling the signal to specific frequency ds_freq, and make the data\n",
    "     with zero mean if zero_mean is True\"\"\"\n",
    "    ori_time_seq = np.array(signal.timestamps)\n",
    "    ori_value_seq = np.array(signal.values)\n",
    "    if zero_mean:\n",
    "        ori_value_seq = ori_value_seq - np.mean(ori_value_seq)\n",
    "    dt = 1./ds_freq\n",
    "    time_seq = np.arange(start=np.min(ori_time_seq),\n",
    "                         stop=np.max(ori_time_seq),\n",
    "                         step=dt)\n",
    "    value_seq = np.interp(time_seq, ori_time_seq, ori_value_seq)\n",
    "    return value_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run this often\n",
    "train_dir = '/kaggle/input/mobile-health-2023-path-detection/data/train/'\n",
    "all_train_f = [os.path.join(train_dir, f) for f in os.listdir(train_dir)]\n",
    "all_train_f.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f, test_f = train_test_split(all_train_f, test_size=0.4, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feat_vec(sm):\n",
    "    \"\"\" return a list containing feature vectors of all the 10s non-overlapping windows\"\"\"\n",
    "    WINDOW = 2000  # 10s window\n",
    "    feat_vecs = []\n",
    "    df1s = []\n",
    "    df2s = []\n",
    "    dfb2s = []\n",
    "    sf = 50.0\n",
    "    for i in range(0, len(sm) - WINDOW, WINDOW):\n",
    "        data = sm[i:i+WINDOW]\n",
    "        low1 = 0.3\n",
    "        high1 = 15\n",
    "        low2 = 0.6\n",
    "        high2 = 2.5\n",
    "        nperseg = 2 / low1 * sf\n",
    "        freqs, psd = signal.welch(data, sf, nperseg=nperseg)\n",
    "        BAND1 = np.logical_and(freqs >= low1, freqs <= high1)\n",
    "        BAND2 = np.logical_and(freqs >= low2, freqs <= high2)\n",
    "        freq_res = freqs[1] - freqs[0]\n",
    "        # compuate total power\n",
    "        total_power = simpson(psd[BAND1], dx=freq_res)\n",
    "\n",
    "        # compute dominant frequencies for BAND1, BAND2\n",
    "        idx_p1 = psd[BAND1].argsort()[-1]\n",
    "        df1 = low1 + freq_res * idx_p1\n",
    "        pdf1 = simpson(psd[BAND1][idx_p1:idx_p1+2], dx=freq_res)\n",
    "        df1s.append(df1)\n",
    "\n",
    "        idx_p2 = psd[BAND1].argsort()[-2]\n",
    "        df2 = low1 + freq_res * idx_p2\n",
    "        pdf2 = simpson(psd[BAND1][idx_p2:idx_p2+2], dx=freq_res)\n",
    "        df2s.append(df2)\n",
    "\n",
    "        idx_b2 = psd[BAND2].argsort()[-1]\n",
    "        dfb2 = low2 + freq_res * idx_b2\n",
    "        pdfb2 = simpson(psd[BAND2][idx_b2:idx_b2+2], dx=freq_res)\n",
    "        dfb2s.append(dfb2)\n",
    "\n",
    "        ratio_pdf1_tot = pdf1 / total_power\n",
    "\n",
    "        if i != 0:\n",
    "            ratio_curr_prev_df1 = df1s[-1] / df1s[-2]\n",
    "            ratio_curr_prev_df2 = df2s[-1] / df2s[-2]\n",
    "            ratio_curr_prev_dfb2 = dfb2s[-1] / dfb2s[-2]\n",
    "        else:\n",
    "            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2 = \\\n",
    "                1.0, 1.0, 1.0\n",
    "\n",
    "        R1 = simpson(psd[freqs <= 3], dx=freq_res) / total_power\n",
    "        R2 = simpson(psd[freqs > 3], dx=freq_res) / total_power\n",
    "\n",
    "        feat_vec = [\n",
    "            np.mean(data),\n",
    "            np.std(data),\n",
    "            df1, pdf1, df2, pdf2, dfb2, pdfb2,\n",
    "            ratio_pdf1_tot,\n",
    "            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2,\n",
    "            R1, R2]\n",
    "        feat_vecs.append(feat_vec)\n",
    "    return feat_vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sm(ax, ay, az, normalize=False):\n",
    "    sm = np.sqrt(np.sum(np.square([ax, ay, az]), axis=0))\n",
    "    if normalize:\n",
    "        return sm - np.mean(sm)\n",
    "    else:\n",
    "        return sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_accelerometer(trace: Recording, use_zc=True):\n",
    "    if use_zc:\n",
    "        ax = parse(trace.data['ax'])\n",
    "        ay = parse(trace.data['ay'])\n",
    "        az = parse(trace.data['az'])\n",
    "    else:\n",
    "        ax = trace.data['ax']\n",
    "        ay = trace.data['ay']\n",
    "        az = trace.data['az']\n",
    "    return ax, ay, az\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for f in tqdm(train_f):\n",
    "    t = Recording(f, no_labels=False, mute=True)\n",
    "    ax, ay, az = parse_accelerometer(t)\n",
    "    label = t.labels['board_loc']\n",
    "    sm = compute_sm(ax, ay, az, normalize=True)\n",
    "    fv = encode_feat_vec(sm)\n",
    "    X_train.extend(fv)\n",
    "    y_train.extend([label] * len(fv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree version\n",
    "class WatchLocDetector(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        selector = np.array([fv[1] > 0.1 for fv in X])\n",
    "        _X = X[selector]\n",
    "        if isinstance(y, int):\n",
    "            _y = [y] * len(_X)\n",
    "        else:\n",
    "            _y = y[selector]\n",
    "        self.clf.fit(_X, _y)\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
    "\n",
    "    def predict_fv(self, X):\n",
    "        win_res = self.clf.predict(X)\n",
    "        return stats.mode(win_res).mode[0]\n",
    "\n",
    "    def predict(self, traces):\n",
    "        # assume array\n",
    "        if hasattr(traces, '__len__'):\n",
    "            res = np.zeros(len(traces), dtype=int)\n",
    "            _traces = traces\n",
    "        else:\n",
    "            res = np.zeros(1, dtype=int)\n",
    "            _traces = [traces]\n",
    "        i = 0\n",
    "        for trace in _traces:\n",
    "            if isinstance(trace, Recording):\n",
    "                ax, ay, az = parse_accelerometer(trace)\n",
    "                sm = compute_sm(ax, ay, az, normalize=True)\n",
    "                feat_vec = encode_feat_vec(sm)\n",
    "            else:\n",
    "                feat_vec = trace\n",
    "            win_res = self.clf.predict(feat_vec)\n",
    "            res[i] = stats.mode(win_res).mode[0]\n",
    "            i += 1\n",
    "        if len(res) == 1:\n",
    "            return res[0]\n",
    "        else:\n",
    "            return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchloc_detector = WatchLocDetector()\n",
    "watchloc_detector.fit(np.array(X_train), np.array(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(watchloc_detector, '/kaggle/working/watchloc_detector.joblib')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
