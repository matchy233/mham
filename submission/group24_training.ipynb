{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T10:39:18.538601Z","iopub.status.busy":"2023-05-17T10:39:18.536372Z","iopub.status.idle":"2023-05-17T10:39:18.575185Z","shell.execute_reply":"2023-05-17T10:39:18.574326Z","shell.execute_reply.started":"2023-05-17T10:39:18.538527Z"},"trusted":true},"outputs":[],"source":["# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n","\n","# Team members (e-mail, legi):\n","# chozhang@student.ethz.ch, 22-945-562\n","# minghli@student.ethz.ch, 22-953-293\n","# changli@student.ethz.ch, 22-944-474\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:20:17.807858Z","iopub.status.busy":"2023-05-17T14:20:17.807414Z","iopub.status.idle":"2023-05-17T14:20:17.838797Z","shell.execute_reply":"2023-05-17T14:20:17.837863Z","shell.execute_reply.started":"2023-05-17T14:20:17.807823Z"},"trusted":true},"outputs":[],"source":["from typing import *\n","import os\n","import sys\n","curr_environ = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n","if curr_environ != 'Localhost':\n","    sys.path.append('/kaggle/input/mobile-health-2023-path-detection')\n","    input_dir = '/kaggle/input/mobile-health-2023-path-detection'\n","else:\n","    input_dir = os.path.abspath('')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:20:17.841559Z","iopub.status.busy":"2023-05-17T14:20:17.841140Z","iopub.status.idle":"2023-05-17T14:20:18.205368Z","shell.execute_reply":"2023-05-17T14:20:18.204468Z","shell.execute_reply.started":"2023-05-17T14:20:17.841520Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","import pandas as pd\n","\n","# progress bar\n","from tqdm import tqdm\n","from time import time\n","\n","# utilty\n","from Lilygo.Recording import Recording\n","from Lilygo.Dataset import Dataset\n","from os import listdir\n","from os.path import isfile, join\n","\n","# plotting\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:22:21.895543Z","iopub.status.busy":"2023-05-17T14:22:21.894689Z","iopub.status.idle":"2023-05-17T14:22:22.743560Z","shell.execute_reply":"2023-05-17T14:22:22.742642Z","shell.execute_reply.started":"2023-05-17T14:22:21.895503Z"},"trusted":true},"outputs":[],"source":["# for signal processing and calculations\n","from scipy import signal\n","from scipy.integrate import simpson\n","from scipy import stats\n","\n","from sklearn import tree\n","\n","# dump and load model\n","from joblib import dump, load\n","\n","# for tuning parameters\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","\n","# for skeleton\n","from sklearn.base import BaseEstimator\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:22:24.379992Z","iopub.status.busy":"2023-05-17T14:22:24.379530Z","iopub.status.idle":"2023-05-17T14:22:24.387505Z","shell.execute_reply":"2023-05-17T14:22:24.386699Z","shell.execute_reply.started":"2023-05-17T14:22:24.379960Z"},"trusted":true},"outputs":[],"source":["### signal processing functions ###\n","def parse(signal, ds_freq: float = 20.0, zero_mean: bool = False):\n","    \"\"\"downsampling the signal to specific frequency ds_freq, and make the data\n","     with zero mean if zero_mean is True\"\"\"\n","    ori_time_seq = np.array(signal.timestamps)\n","    ori_value_seq = np.array(signal.values)\n","    if zero_mean:\n","        ori_value_seq = ori_value_seq - np.mean(ori_value_seq)\n","    dt = 1./ds_freq\n","    time_seq = np.arange(start=np.min(ori_time_seq),\n","                         stop=np.max(ori_time_seq),\n","                         step=dt)\n","    value_seq = np.interp(time_seq, ori_time_seq, ori_value_seq)\n","    return value_seq"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:22:26.718208Z","iopub.status.busy":"2023-05-17T14:22:26.717356Z","iopub.status.idle":"2023-05-17T14:22:26.752643Z","shell.execute_reply":"2023-05-17T14:22:26.751713Z","shell.execute_reply.started":"2023-05-17T14:22:26.718164Z"},"trusted":true},"outputs":[],"source":["# do not run this often\n","train_dir = '/kaggle/input/mobile-health-2023-path-detection/data/train/'\n","all_train_f = [os.path.join(train_dir, f) for f in os.listdir(train_dir)]\n","all_train_f.sort()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:22:29.087993Z","iopub.status.busy":"2023-05-17T14:22:29.086832Z","iopub.status.idle":"2023-05-17T14:22:29.095389Z","shell.execute_reply":"2023-05-17T14:22:29.093891Z","shell.execute_reply.started":"2023-05-17T14:22:29.087933Z"},"trusted":true},"outputs":[],"source":["# watch location train and test\n","train_f, test_f = train_test_split(all_train_f, test_size=0.4, random_state=0)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:22:30.888876Z","iopub.status.busy":"2023-05-17T14:22:30.888441Z","iopub.status.idle":"2023-05-17T14:22:30.905902Z","shell.execute_reply":"2023-05-17T14:22:30.904309Z","shell.execute_reply.started":"2023-05-17T14:22:30.888841Z"},"trusted":true},"outputs":[],"source":["def encode_feat_vec(sm):\n","    \"\"\" return a list containing feature vectors of all the 10s non-overlapping windows\"\"\"\n","    WINDOW = 2000  # 10s window\n","    feat_vecs = []\n","    df1s = []\n","    df2s = []\n","    dfb2s = []\n","    sf = 50.0\n","    for i in range(0, len(sm) - WINDOW, WINDOW):\n","        data = sm[i:i+WINDOW]\n","        low1 = 0.3\n","        high1 = 15\n","        low2 = 0.6\n","        high2 = 2.5\n","        nperseg = 2 / low1 * sf\n","        freqs, psd = signal.welch(data, sf, nperseg=nperseg)\n","        BAND1 = np.logical_and(freqs >= low1, freqs <= high1)\n","        BAND2 = np.logical_and(freqs >= low2, freqs <= high2)\n","        freq_res = freqs[1] - freqs[0]\n","        # compuate total power\n","        total_power = simpson(psd[BAND1], dx=freq_res)\n","\n","        # compute dominant frequencies for BAND1, BAND2\n","        idx_p1 = psd[BAND1].argsort()[-1]\n","        df1 = low1 + freq_res * idx_p1\n","        pdf1 = simpson(psd[BAND1][idx_p1:idx_p1+2], dx=freq_res)\n","        df1s.append(df1)\n","\n","        idx_p2 = psd[BAND1].argsort()[-2]\n","        df2 = low1 + freq_res * idx_p2\n","        pdf2 = simpson(psd[BAND1][idx_p2:idx_p2+2], dx=freq_res)\n","        df2s.append(df2)\n","\n","        idx_b2 = psd[BAND2].argsort()[-1]\n","        dfb2 = low2 + freq_res * idx_b2\n","        pdfb2 = simpson(psd[BAND2][idx_b2:idx_b2+2], dx=freq_res)\n","        dfb2s.append(dfb2)\n","\n","        ratio_pdf1_tot = pdf1 / total_power\n","\n","        if i != 0:\n","            ratio_curr_prev_df1 = df1s[-1] / df1s[-2]\n","            ratio_curr_prev_df2 = df2s[-1] / df2s[-2]\n","            ratio_curr_prev_dfb2 = dfb2s[-1] / dfb2s[-2]\n","        else:\n","            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2 = \\\n","                1.0, 1.0, 1.0\n","\n","        R1 = simpson(psd[freqs <= 3], dx=freq_res) / total_power\n","        R2 = simpson(psd[freqs > 3], dx=freq_res) / total_power\n","\n","        feat_vec = [\n","            np.mean(data),\n","            np.std(data),\n","            df1, pdf1, df2, pdf2, dfb2, pdfb2,\n","            ratio_pdf1_tot,\n","            ratio_curr_prev_df1, ratio_curr_prev_df2, ratio_curr_prev_dfb2,\n","            R1, R2]\n","        feat_vecs.append(feat_vec)\n","    return feat_vecs\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:22:34.870828Z","iopub.status.busy":"2023-05-17T14:22:34.869460Z","iopub.status.idle":"2023-05-17T14:22:34.878376Z","shell.execute_reply":"2023-05-17T14:22:34.876716Z","shell.execute_reply.started":"2023-05-17T14:22:34.870736Z"},"trusted":true},"outputs":[],"source":["def compute_sm(ax, ay, az, normalize=False):\n","    sm = np.sqrt(np.sum(np.square([ax, ay, az]), axis=0))\n","    if normalize:\n","        return sm - np.mean(sm)\n","    else:\n","        return sm\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T14:22:37.077751Z","iopub.status.busy":"2023-05-17T14:22:37.077314Z","iopub.status.idle":"2023-05-17T14:22:37.087535Z","shell.execute_reply":"2023-05-17T14:22:37.086204Z","shell.execute_reply.started":"2023-05-17T14:22:37.077715Z"},"trusted":true},"outputs":[],"source":["def parse_accelerometer(trace: Recording, use_zc=True):\n","    if use_zc:\n","        ax = parse(trace.data['ax'])\n","        ay = parse(trace.data['ay'])\n","        az = parse(trace.data['az'])\n","    else:\n","        ax = trace.data['ax'].values\n","        ay = trace.data['ay'].values\n","        az = trace.data['az'].values\n","    return ax, ay, az\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T10:41:17.703816Z","iopub.status.busy":"2023-05-17T10:41:17.703371Z","iopub.status.idle":"2023-05-17T10:50:05.592951Z","shell.execute_reply":"2023-05-17T10:50:05.591699Z","shell.execute_reply.started":"2023-05-17T10:41:17.703780Z"},"trusted":true},"outputs":[],"source":["X_train = []\n","y_train = []\n","\n","for f in tqdm(train_f):\n","    t = Recording(f, no_labels=False, mute=True)\n","    ax, ay, az = parse_accelerometer(t, use_zc=False)\n","    label = t.labels['board_loc']\n","    sm = compute_sm(ax, ay, az, normalize=True)\n","    fv = encode_feat_vec(sm)\n","    X_train.extend(fv)\n","    y_train.extend([label] * len(fv))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T10:40:22.451435Z","iopub.status.busy":"2023-05-17T10:40:22.451020Z","iopub.status.idle":"2023-05-17T10:40:22.465989Z","shell.execute_reply":"2023-05-17T10:40:22.464713Z","shell.execute_reply.started":"2023-05-17T10:40:22.451403Z"},"trusted":true},"outputs":[],"source":["# decision tree version\n","class WatchLocDetector(BaseEstimator):\n","    def __init__(self):\n","        self.clf = tree.DecisionTreeClassifier()\n","\n","    def fit(self, X, y):\n","        selector = np.array([fv[1] > 0.1 for fv in X])\n","        _X = X[selector]\n","        if isinstance(y, int):\n","            _y = [y] * len(_X)\n","        else:\n","            _y = y[selector]\n","        self.clf.fit(_X, _y)\n","\n","    def score(self, X, y, sample_weight=None):\n","        from sklearn.metrics import accuracy_score\n","        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n","\n","    def predict_fv(self, X):\n","        win_res = self.clf.predict(X)\n","        return stats.mode(win_res).mode[0]\n","\n","    def predict(self, traces):\n","        # assume array\n","        if hasattr(traces, '__len__'):\n","            res = np.zeros(len(traces), dtype=int)\n","            _traces = traces\n","        else:\n","            res = np.zeros(1, dtype=int)\n","            _traces = [traces]\n","        i = 0\n","        for trace in _traces:\n","            if isinstance(trace, Recording):\n","                ax, ay, az = parse_accelerometer(trace)\n","                sm = compute_sm(ax, ay, az, normalize=True)\n","                feat_vec = encode_feat_vec(sm)\n","            else:\n","                feat_vec = trace\n","            win_res = self.clf.predict(feat_vec)\n","            res[i] = stats.mode(win_res).mode[0]\n","            i += 1\n","        if len(res) == 1:\n","            return res[0]\n","        else:\n","            return res\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# activity recognition train and test\n","X_train_act = []\n","y_train_act = []\n","test_f_act = []\n","for f in tqdm(all_train_f):\n","    t = Recording(f, no_labels=False, mute=True)\n","    # use homogeneous traces to train\n","    if len(t.labels['activities']) == 1:\n","        ax, ay, az = parse_accelerometer(t, use_zc=False)\n","        sm = compute_sm(ax, ay, az, normalize=True)\n","        fv = encode_feat_vec(sm)\n","        X_train_act.extend(fv)\n","        y_train_act.extend(t.labels['activities'] * len(fv))\n","    else:\n","        test_f_act.append(f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ActivityRecognizer(BaseEstimator):\n","    def __init__(self, count_tresh=2):\n","        self.clf = tree.DecisionTreeClassifier()\n","        self.count_thresh = count_tresh\n","\n","    def fit(self, X, y): # X is an array of windows\n","        selector = np.array([fv[1] > 0.1 for fv in X])\n","        _X = X[selector]\n","        if isinstance(y, int):\n","            _y = [y] * len(_X)\n","        else:\n","            _y = y[selector]\n","        self.clf.fit(_X, _y)\n","\n","    def score(self, X, y, sample_weight=None):\n","        y_predict = self.predict(X)\n","        tot_score = 0\n","        for true, pred in zip(y, y_predict):\n","            # walk 1, run 2, cycle 3\n","            # 0.05, 0.05, 0.1\n","            true_v = [1 in true, 2 in true, 3 in true]\n","            pred_v = [1 in pred, 2 in pred, 3 in pred]\n","            score = int(true_v[0] == pred_v[0]) + \\\n","                    int(true_v[1] == pred_v[1]) + \\\n","                    int(true_v[2] == pred_v[2])\n","            score /= 4\n","            tot_score += score\n","        return tot_score / len(y_predict)\n","\n","    def predict_fv(self, X):\n","        win_res = self.clf.predict(X)\n","        values, counts = np.unique(win_res, return_counts=True)\n","        return [values[j] \n","                for j, count in enumerate(counts) if count >= self.count_thresh]\n","\n","    def predict(self, traces):\n","        # assume array\n","        if hasattr(traces, '__len__'):\n","            res = [0] * len(traces)\n","            _traces = traces\n","        else:\n","            res = [0]\n","            _traces = [traces]\n","        i = 0\n","        for trace in _traces:\n","            if isinstance(trace, Recording):\n","                ax, ay, az = parse_accelerometer(trace, use_zc=False)\n","                sm = compute_sm(ax, ay, az, normalize=True)\n","                feat_vec = encode_feat_vec(sm)\n","            else:\n","                feat_vec = trace\n","            # will get an activity prediction for each window\n","            win_res = self.clf.predict(feat_vec) \n","            values, counts = np.unique(win_res, return_counts=True)\n","            res[i] = [values[j] \n","                      for j, count in enumerate(counts) if count >= self.count_thresh]\n","            i += 1\n","        return res\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T10:59:10.863890Z","iopub.status.busy":"2023-05-17T10:59:10.862535Z","iopub.status.idle":"2023-05-17T10:59:11.018172Z","shell.execute_reply":"2023-05-17T10:59:11.016971Z","shell.execute_reply.started":"2023-05-17T10:59:10.863843Z"},"trusted":true},"outputs":[],"source":["watchloc_detector = WatchLocDetector()\n","watchloc_detector.fit(np.array(X_train), np.array(y_train))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["act_recognizer = ActivityRecognizer()\n","act_recognizer.fit(X_train_act, y_train_act)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-17T10:59:12.656969Z","iopub.status.busy":"2023-05-17T10:59:12.656511Z","iopub.status.idle":"2023-05-17T10:59:12.669207Z","shell.execute_reply":"2023-05-17T10:59:12.667946Z","shell.execute_reply.started":"2023-05-17T10:59:12.656933Z"},"trusted":true},"outputs":[],"source":["dump(watchloc_detector.clf, '/kaggle/working/group24_model_watchloc.joblib')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dump(act_recognizer.clf, '/kaggle/working/group24_model_activity.joblib')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy.spatial.transform import Rotation\n","\n","def madgwick_update(q, gyro, accel, mag, beta, dt):\n","    q = np.array([q[0], q[1], q[2], q[3]])\n","\n","    f_g = np.array([2 * (q[1] * q[3] - q[0] * q[2]) - accel[0],\n","                    2 * (q[0] * q[1] + q[2] * q[3]) - accel[1],\n","                    2 * (0.5 - q[1]**2 - q[2]**2) - accel[2]])\n","\n","    f_b = np.array([2 * (q[1] * q[2] + q[0] * q[3]) - mag[0],\n","                    2 * (q[0] * q[1] - q[2] * q[3]) - mag[1],\n","                    2 * (q[0]**2 + q[3]**2 - 0.5) - mag[2]])\n","\n","    j_g = np.array([[-2 * q[2], 2 * q[3], -2 * q[0], 2 * q[1]],\n","                    [2 * q[1],  2 * q[0],  2 * q[3], 2 * q[2]],\n","                    [0,         -4 * q[1], -4 * q[2],0]])\n","\n","    j_b = np.array([[2 * q[3],  2 * q[2],  2 * q[1], 2 * q[0]],\n","                    [2 * q[0],  -2 * q[1], -2 * q[2],2 * q[3]],\n","                    [-4 * q[0], -4 * q[3],  0,       0]])\n","\n","    step_size = beta * dt\n","    q += step_size * (j_g.T @ f_g + j_b.T @ f_b)\n","    q /= np.linalg.norm(q)\n","    return q\n","\n","class PathDetector(BaseEstimator):\n","    # hack labels via GPS, delete later\n","    def __init__(self):\n","        pass\n","    \n","    def extract(self,trace):\n","        data = trace.data\n","        fea_alti = self.get_fea_alti(data['altitude'])\n","        fea_ori = self.get_fea_ori(data['ax'],data['ay'],data['az'],data['gx'],data['gy'],data['gz'],data['mx'],data['my'],data['mz'])\n","        fea = fea_alti + fea_ori\n","        return fea\n","\n","    # required\n","    def fit(self, data, labels):\n","        self.clf = RandomForestClassifier(min_samples_leaf=10, max_depth=15, max_features=12)\n","        self.clf.fit(data, labels)\n","        print('fit score', self.clf.score(data,labels))\n","\n","    # required    \n","    def predict(self, feature):\n","        fea = [feature]\n","        res = self.clf.predict(fea)[0]\n","        return res\n","    \n","    def get_fea_alti(self, alti):\n","        t, alti = parse(alti)\n","        t = t[600:]\n","        alti = alti[600:]\n","        alti = lp_filter(alti, .998)\n","        alti = alti - np.min(alti)\n","        alti[alti>60] = 60\n","        alti /= 60.0\n","        t = (t-np.min(t)) / (np.max(t)-np.min(t))\n","        fea_alti = split_fea(t, alti, 5, lambda x: np.nanpercentile(x,50))\n","        return fea_alti\n","    \n","    def get_fea_ori(self, ax, ay, az, gx, gy, gz, mx, my, mz):\n","        deg2rad = np.pi/180\n","        t, ax = parse(ax)\n","        t, ay = parse(ay)\n","        t, az = parse(az)\n","        t, gx = parse(gx)\n","        t, gy = parse(gy)\n","        t, gz = parse(gz)\n","        t, mx = parse(mx)\n","        t, my = parse(my)\n","        t, mz = parse(mz)\n","        gx, gy, gz = gx * deg2rad, gy * deg2rad, gz * deg2rad\n","        acc = np.array([ax,ay,az])\n","        gyro = np.array([gx,gy,gz])\n","        mag = np.array([mx,my,mz])\n","\n","        acc /= (1e-8 + np.linalg.norm(acc,ord=2,axis=0,keepdims=True))\n","        mag /= (1e-8 + np.linalg.norm(mag,ord=2,axis=0,keepdims=True))\n","\n","        dt = t[1] - t[0]\n","        beta = 0.1  # Madgwick filter gain\n","        \n","        ref_acc_vector = np.array([[0, 0, 1],[0, 0, 1],[0, 0, 1]])  # a - g for a = 0\n","        rotation_matrix = Rotation.align_vectors(ref_acc_vector, [acc[:,0],acc[:,1],acc[:,2]])[0].as_matrix()\n","        q = Rotation.from_matrix(rotation_matrix).as_quat()\n","        \n","        quats = []\n","        yaws = []\n","        for i in range(len(t)):\n","            q = madgwick_update(q, gyro[:,i], acc[:,i], mag[:,i], beta, dt)\n","            quats.append(q)\n","            try:\n","                yaw = Rotation.from_quat(q).as_euler('xyz')[-1]\n","            except: \n","                yaw = 0\n","            yaws.append(yaw)\n","        t, yaws = np.array(t[400:]), np.array(yaws[400:])\n","        yaws -= yaws[0]  # sometime can jump 2pi\n","        sinyaws, cosyaws = np.sin(yaws), np.cos(yaws)\n","        sinyaws, cosyaws = lp_filter(sinyaws, .97), lp_filter(cosyaws, .97)\n","        fea_sinyaw = split_fea(t, sinyaws, 10)\n","        fea_cosyaw = split_fea(t, cosyaws, 10)\n","        fea_ori = fea_sinyaw + fea_cosyaw\n","        return fea_ori\n","\n","path_detector = PathDetector()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dir_traces_train = '/kaggle/input/mobile-health-2023-path-detection/data/train'\n","filenames_train = [join(dir_traces_train, f) for f in listdir(dir_traces_train) if isfile(join(dir_traces_train, f))]\n","filenames_train.sort()\n","labels = []\n","features = []\n","for f in filenames_train:\n","    trace = Recording(f, no_labels=False, mute=True)\n","    label = trace.labels['path_idx']\n","    labels.append(label)\n","    fea = path_detector.extract(trace)\n","    features.append(fea)\n","    print(f, label, len(fea), end = '     \\r')\n","    \n","labels = np.array(labels)\n","features = np.array(features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.save('/kaggle/working/pathfea.npy', features)\n","np.save('/kaggle/working/pathlabels.npy', labels)\n","print(features.shape, labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = np.load('pathfea.npy')\n","labels = np.load('pathlabels.npy')\n","\n","# clf = RandomForestClassifier(min_samples_leaf=10, max_depth=15, max_features=12)\n","# scores = cross_val_score(clf, features, labels, cv=5, scoring='accuracy')\n","# print(scores, np.mean(scores), np.std(scores))\n","path_detector.fit(features, labels)\n","path_detector.predict(features[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dump(path_detector.clf, '/kaggle/working/group24_model_pathindex.joblib')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the path of all traces and encode features\n","dir_traces = '/kaggle/input/mobile-health-2023-path-detection/data/test'\n","filenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\n","filenames.sort()\n","\n","pathdec_fea_test = []\n","for i, filename in enumerate(filenames):\n","    trace = Recording(filename, no_labels=True, mute=True)\n","    pathdec_fea_test.append(path_detector.extract(trace))\n","    print(filename, end = '   \\r')\n","pathdec_fea_test = np.array(pathdec_fea_test)\n","print(pathdec_fea_test.shape)\n","\n","np.save('/kaggle/working/group24_features_pathindex.npy', pathdec_fea_test)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
