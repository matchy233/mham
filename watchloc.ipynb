{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n\n# Team members (e-mail, legi):\n# chozhang@student.ethz.ch, 22-945-562\n# minghli@student.ethz.ch, 22-953-293\n# changli@student.ethz.ch, 22-944-474","metadata":{"papermill":{"duration":0.030574,"end_time":"2023-05-14T19:00:20.613534","exception":false,"start_time":"2023-05-14T19:00:20.582960","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Sequence","metadata":{"papermill":{"duration":0.028067,"end_time":"2023-05-14T19:00:20.652708","exception":false,"start_time":"2023-05-14T19:00:20.624641","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-17T12:24:02.797616Z","iopub.execute_input":"2023-05-17T12:24:02.798070Z","iopub.status.idle":"2023-05-17T12:24:02.835745Z","shell.execute_reply.started":"2023-05-17T12:24:02.798032Z","shell.execute_reply":"2023-05-17T12:24:02.833782Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\ncurr_environ = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\nif curr_environ != 'Localhost': \n    sys.path.append('/kaggle/input/mobile-health-2023-path-detection')\n    input_dir = '/kaggle/input/mobile-health-2023-path-detection'\nelse:\n    input_dir = os.path.abspath('')","metadata":{"papermill":{"duration":0.020526,"end_time":"2023-05-14T19:00:20.683520","exception":false,"start_time":"2023-05-14T19:00:20.662994","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-17T12:24:09.721739Z","iopub.execute_input":"2023-05-17T12:24:09.722642Z","iopub.status.idle":"2023-05-17T12:24:09.729273Z","shell.execute_reply.started":"2023-05-17T12:24:09.722602Z","shell.execute_reply":"2023-05-17T12:24:09.727962Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom Lilygo.Recording import Recording\nfrom Lilygo.Dataset import Dataset\nfrom os import listdir\nfrom os.path import isfile, join","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.613274,"end_time":"2023-05-14T19:00:21.307360","exception":false,"start_time":"2023-05-14T19:00:20.694086","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2023-05-17T12:24:14.113522Z","iopub.execute_input":"2023-05-17T12:24:14.113941Z","iopub.status.idle":"2023-05-17T12:24:14.121327Z","shell.execute_reply.started":"2023-05-17T12:24:14.113907Z","shell.execute_reply":"2023-05-17T12:24:14.119614Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"papermill":{"duration":0.023548,"end_time":"2023-05-14T19:00:21.341683","exception":false,"start_time":"2023-05-14T19:00:21.318135","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-17T12:24:16.744545Z","iopub.execute_input":"2023-05-17T12:24:16.744975Z","iopub.status.idle":"2023-05-17T12:24:16.750598Z","shell.execute_reply.started":"2023-05-17T12:24:16.744940Z","shell.execute_reply":"2023-05-17T12:24:16.749111Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# for signal processing and calculations\nfrom scipy import signal\n\n# for tuning parameters\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.base import BaseEstimator\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"papermill":{"duration":1.529282,"end_time":"2023-05-14T19:00:22.882142","exception":false,"start_time":"2023-05-14T19:00:21.352860","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-17T12:58:36.109683Z","iopub.execute_input":"2023-05-17T12:58:36.110156Z","iopub.status.idle":"2023-05-17T12:58:36.561872Z","shell.execute_reply.started":"2023-05-17T12:58:36.110120Z","shell.execute_reply":"2023-05-17T12:58:36.560338Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"### signal processing functions ###\ndef parse(signal, ds_freq:float=20.0, zero_mean:bool=False):\n    \"\"\"downsampling the signal to specific frequency ds_freq, and make the data\n     with zero mean if zero_mean is True\"\"\"\n    ori_time_seq = np.array(signal.timestamps)\n    ori_value_seq = np.array(signal.values)\n    if zero_mean: ori_value_seq = ori_value_seq - np.mean(ori_value_seq)\n    dt = 1./ds_freq\n    time_seq = np.arange(start=np.min(ori_time_seq), stop=np.max(ori_time_seq), step=dt)\n    value_seq = np.interp(time_seq, ori_time_seq, ori_value_seq)\n    return time_seq, value_seq\n    \ndef bp_filter(value_seq, fp:float=3, fs:float=20.0):\n    \"\"\"apply band pass filter to the sequence. fp is the threshold frequency,\n     and fs is the sampling frequency.\"\"\"\n    sos = signal.butter(N=4, Wn=[0.5,fp], btype='bandpass', fs=fs, output='sos')\n    filtered = signal.sosfilt(sos, value_seq)\n    return filtered\n\ndef lp_filter(value_seq, alpha=0.95):\n    x = value_seq[0]\n    a = []\n    for v in value_seq:\n        x = x * alpha + v * (1-alpha)\n        a.append(x)    \n    return np.array(a)\n    \ndef get_envelop(value_seq, \n                fs:float=20, \n                half_window_size:float=0.5, \n                _min:float=20., \n                _max:float=500.):\n    \"\"\"\n    get the envelop as the adaptive local norm of the signal, currently the mode\n     of vector (no negative values). The envelop is calculated by the maximum in\n     a window, half_window_size is the seconds of time. _min and _max for clip.\n    \"\"\"\n    half_win = int(fs*half_window_size)\n    seq = np.concatenate([np.zeros((half_win,)),value_seq,np.zeros((half_win,))])\n    envelop = np.array([np.max(seq[k-half_win:k+half_win+1]) \n                        for k in range(half_win,half_win+len(value_seq))])\n    return np.clip(envelop, _min, _max)\n\ndef split_fea(t, v, n_split, fn = lambda x: np.percentile(x, 50)):\n    tmin, tmax = np.min(t)-1e-8, np.max(t)+1e-8\n    t_split = np.linspace(tmin, tmax, n_split+1, endpoint=True)\n    outputs = []\n    for i in range(n_split):\n        start, end = t_split[i], t_split[i+1]\n        array = v[(t>start) & (t<end)]\n        fea = fn(array)\n        outputs.append(fea)\n    return outputs","metadata":{"papermill":{"duration":0.03035,"end_time":"2023-05-14T19:00:22.923201","exception":false,"start_time":"2023-05-14T19:00:22.892851","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-17T12:35:30.766771Z","iopub.execute_input":"2023-05-17T12:35:30.767209Z","iopub.status.idle":"2023-05-17T12:35:30.786435Z","shell.execute_reply.started":"2023-05-17T12:35:30.767172Z","shell.execute_reply":"2023-05-17T12:35:30.785085Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Tasks\n\n## Step Count","metadata":{"papermill":{"duration":0.010124,"end_time":"2023-05-14T19:00:22.944999","exception":false,"start_time":"2023-05-14T19:00:22.934875","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n## Path Index","metadata":{"papermill":{"duration":0.009367,"end_time":"2023-05-14T19:01:48.174316","exception":false,"start_time":"2023-05-14T19:01:48.164949","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"All traces must contain GPS data, so can use this for sanity check.","metadata":{"papermill":{"duration":0.009077,"end_time":"2023-05-14T19:01:48.192915","exception":false,"start_time":"2023-05-14T19:01:48.183838","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from scipy.spatial.transform import Rotation\n\ndef madgwick_update(q, gyro, accel, mag, beta, dt):\n    q = np.array([q[0], q[1], q[2], q[3]])\n\n    f_g = np.array([2 * (q[1] * q[3] - q[0] * q[2]) - accel[0],\n                    2 * (q[0] * q[1] + q[2] * q[3]) - accel[1],\n                    2 * (0.5 - q[1]**2 - q[2]**2) - accel[2]])\n\n    f_b = np.array([2 * (q[1] * q[2] + q[0] * q[3]) - mag[0],\n                    2 * (q[0] * q[1] - q[2] * q[3]) - mag[1],\n                    2 * (q[0]**2 + q[3]**2 - 0.5) - mag[2]])\n\n    j_g = np.array([[-2 * q[2], 2 * q[3], -2 * q[0], 2 * q[1]],\n                    [2 * q[1],  2 * q[0],  2 * q[3], 2 * q[2]],\n                    [0,         -4 * q[1], -4 * q[2],0]])\n\n    j_b = np.array([[2 * q[3],  2 * q[2],  2 * q[1], 2 * q[0]],\n                    [2 * q[0],  -2 * q[1], -2 * q[2],2 * q[3]],\n                    [-4 * q[0], -4 * q[3],  0,       0]])\n\n    step_size = beta * dt\n    q += step_size * (j_g.T @ f_g + j_b.T @ f_b)\n    q /= np.linalg.norm(q)\n    return q\n\nclass PathDetector(BaseEstimator):\n    # hack labels via GPS, delete later\n    def __init__(self):\n        pass\n    \n    def extract(self,trace):\n        data = trace.data\n        fea_alti = self.get_fea_alti(data['altitude'])\n        fea_ori = self.get_fea_ori(data['ax'],data['ay'],data['az'],data['gx'],data['gy'],data['gz'],data['mx'],data['my'],data['mz'])\n\n    # required\n    def fit(self, data, labels):\n        pass\n\n    # required    \n    def predict(self, feature):\n        pass\n    \n    def get_fea_alti(self, alti):\n        t, alti = parse(alti)\n        t = t[600:]\n        alti = alti[600:]\n        alti = lp_filter(alti, .998)\n        alti = alti - np.min(alti)\n        alti[alti>60] = 60\n        alti /= 60.0\n        t = (t-np.min(t)) / (np.max(t)-np.min(t))\n        fea_alti = split_fea(t, alti, 5, lambda x: np.nanpercentile(x,50))\n        return fea_alti\n    \n    def get_fea_ori(self, ax, ay, az, gx, gy, gz, mx, my, mz):\n        deg2rad = np.pi/180\n        t, ax = parse(ax)\n        t, ay = parse(ay)\n        t, az = parse(az)\n        t, gx = parse(gx)\n        t, gy = parse(gy)\n        t, gz = parse(gz)\n        t, mx = parse(mx)\n        t, my = parse(my)\n        t, mz = parse(mz)\n        gx, gy, gz = gx * deg2rad, gy * deg2rad, gz * deg2rad\n        acc = np.array([ax,ay,az])\n        gyro = np.array([gx,gy,gz])\n        mag = np.array([mx,my,mz])\n\n        acc /= np.linalg.norm(acc,ord=2,axis=0,keepdims=True)\n        mag /= np.linalg.norm(mag,ord=2,axis=0,keepdims=True)\n\n        dt = t[1] - t[0]\n        beta = 0.1  # Madgwick filter gain\n        \n        ref_acc_vector = np.array([[0, 0, 1],[0, 0, 1],[0, 0, 1]])  # a - g for a = 0\n        rotation_matrix = Rotation.align_vectors(ref_acc_vector, [acc[:,0],acc[:,1],acc[:,2]])[0].as_matrix()\n        q = Rotation.from_matrix(rotation_matrix).as_quat()\n        \n        quats = []\n        yaws = []\n        for i in range(len(t)):\n            q = madgwick_update(q, gyro[:,i], acc[:,i], mag[:,i], beta, dt)\n            quats.append(q)\n            yaw = Rotation.from_quat(q).as_euler('xyz')[-1]\n            while i>0 and np.abs(yaw-yaws[-1])>3:\n                if yaws[-1] < yaw: yaw -= 2 * np.pi\n                if yaws[-1] > yaw: yaw += 2 * np.pi\n            yaws.append(yaw)\n        t, yaws = np.array(t[450:]), np.array(yaws[450:])\n        t = (t-np.min(t)) / (np.max(t)-np.min(t))\n        yaws = lp_filter(yaws, .98)\n        yaws -= yaws[0]\n        plt.plot(t, yaws)\n\npath_detector = PathDetector()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T13:53:49.771716Z","iopub.execute_input":"2023-05-17T13:53:49.773043Z","iopub.status.idle":"2023-05-17T13:53:49.806660Z","shell.execute_reply.started":"2023-05-17T13:53:49.772990Z","shell.execute_reply":"2023-05-17T13:53:49.805372Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"dir_traces_train = '/kaggle/input/mobile-health-2023-path-detection/data/train'\nfilenames_train = [join(dir_traces_train, f) for f in listdir(dir_traces_train) if isfile(join(dir_traces_train, f))]\nfilenames_train.sort()\nlabels = []\nfor f in filenames_train[:30]:\n    print(f)\n    trace = Recording(f, no_labels=False, mute=True)\n    labels.append(trace.labels['path_idx'])\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T12:37:48.477754Z","iopub.execute_input":"2023-05-17T12:37:48.478257Z","iopub.status.idle":"2023-05-17T12:39:08.277588Z","shell.execute_reply.started":"2023-05-17T12:37:48.478222Z","shell.execute_reply":"2023-05-17T12:39:08.276142Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_001.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_002.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_003.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_004.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_005.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_006.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_007.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_008.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_009.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_010.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_011.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_012.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_013.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_014.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_015.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_016.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_017.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_018.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_019.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_020.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_021.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_022.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_023.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_024.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_025.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_026.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_027.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_028.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_029.json\n/kaggle/input/mobile-health-2023-path-detection/data/train/train_trace_031.json\n[4, 2, 1, 0, 2, 4, 3, 1, 3, 2, 1, 0, 3, 1, 4, 3, 4, 4, 1, 0, 4, 4, 3, 2, 1, 2, 3, 3, 0, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"for f in range(30):\n    if labels[f]==3:\n        trace = Recording(filenames_train[f], no_labels=False, mute=True)\n        path_detector.extract(trace)\nprint(trace.labels['path_idx'])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T13:53:52.120554Z","iopub.execute_input":"2023-05-17T13:53:52.120989Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/845790461.py:80: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n  rotation_matrix = Rotation.align_vectors(ref_acc_vector, [acc[:,0],acc[:,1],acc[:,2]])[0].as_matrix()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n\n## Activity\n\nActivities contained in the data trace and performed for more than 60 s uninterrupted. \n\nOutput as a list of integers: e.g., `[0, 3]` (`0`: standing still, `1`: walk, `2`: run, `3`: cycle). \n\nThese do not need to be in the right order and they do not need to occur multiple times.","metadata":{"papermill":{"duration":0.009368,"end_time":"2023-05-14T19:01:48.240373","exception":false,"start_time":"2023-05-14T19:01:48.231005","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ActivityPredictor(BaseEstimator):\n    # required\n    def __init__(self):\n        pass\n\n    # required\n    def fit(self, data, labels):\n        pass\n\n    # required\n    def predict(self, trace):\n        pass","metadata":{"papermill":{"duration":0.021479,"end_time":"2023-05-14T19:01:48.271307","exception":false,"start_time":"2023-05-14T19:01:48.249828","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-16T19:13:22.878381Z","iopub.status.idle":"2023-05-16T19:13:22.879917Z","shell.execute_reply.started":"2023-05-16T19:13:22.879440Z","shell.execute_reply":"2023-05-16T19:13:22.879481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Prediction","metadata":{"papermill":{"duration":0.009352,"end_time":"2023-05-14T19:01:48.290883","exception":false,"start_time":"2023-05-14T19:01:48.281531","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Get the path of all traces\ndir_traces = '/kaggle/input/mobile-health-2023-path-detection/data/test'\nfilenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\nfilenames.sort()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.105681,"end_time":"2023-05-14T19:01:48.406161","exception":false,"start_time":"2023-05-14T19:01:48.300480","status":"completed"},"pycharm":{"is_executing":true,"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2023-05-16T19:13:22.881074Z","iopub.status.idle":"2023-05-16T19:13:22.881531Z","shell.execute_reply.started":"2023-05-16T19:13:22.881310Z","shell.execute_reply":"2023-05-16T19:13:22.881326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize predictors\nstep_counter = StepCounter()","metadata":{"papermill":{"duration":0.020967,"end_time":"2023-05-14T19:01:48.437792","exception":false,"start_time":"2023-05-14T19:01:48.416825","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-16T19:13:22.882853Z","iopub.status.idle":"2023-05-16T19:13:22.883657Z","shell.execute_reply.started":"2023-05-16T19:13:22.883321Z","shell.execute_reply":"2023-05-16T19:13:22.883374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through all traces and calculate the step count for each trace\nsolution_file = []\nfor filename in filenames:\n    trace = Recording(filename, no_labels=True, mute=True)\n    categorization_results = {'watch_loc': 114514, 'path_idx': 0, 'step_count': 1919810, 'stand': 114514, 'walk': 114514, 'run': 114514, 'cycle': 114514}\n\n    #\n    # Your algorithm goes here\n    # You can access the variable 'watch_loc' in the dictionary 'categorization_results' for example with\n    # categorization_results['watch_loc'] = 1\n    # Make sure, you do not use the gps data and are tolerant for missing data (see task set).\n    # Your program must not crash when single smartphone data traces are missing.\n    #\n    categorization_results['step_count'] = step_counter.predict(trace)\n\n    # Append your calculated results and the id of each trace and category to the solution file\n    trace_id = ''.join([*filename][-8:-5])\n    for counter_label, category in enumerate(categorization_results):\n        solution_file.append([trace_id + f'_{counter_label+1}', categorization_results[category]])\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":39.552158,"end_time":"2023-05-14T19:02:27.999936","exception":false,"start_time":"2023-05-14T19:01:48.447778","status":"completed"},"pycharm":{"is_executing":true,"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2023-05-16T19:13:22.886058Z","iopub.status.idle":"2023-05-16T19:13:22.886461Z","shell.execute_reply.started":"2023-05-16T19:13:22.886286Z","shell.execute_reply":"2023-05-16T19:13:22.886303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write the detected step counts into a .csv file to then upload the .csv file to Kaggle\n# When cross-checking the .csv file on your computer, we recommend using the text editor and NOT excel so that the results are displayed correctly\n# IMPORTANT: Do NOT change the name of the columns ('Id' and 'Category') of the .csv file\nsubmission_file_df = pd.DataFrame(np.asarray(solution_file), columns=['Id', 'Category'])\nsubmission_file_df.to_csv('/kaggle/working/submission.csv', header=['Id', 'Category'], index=False)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.041986,"end_time":"2023-05-14T19:02:28.052947","exception":false,"start_time":"2023-05-14T19:02:28.010961","status":"completed"},"pycharm":{"is_executing":true,"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2023-05-16T19:13:22.887497Z","iopub.status.idle":"2023-05-16T19:13:22.887888Z","shell.execute_reply.started":"2023-05-16T19:13:22.887693Z","shell.execute_reply":"2023-05-16T19:13:22.887709Z"},"trusted":true},"execution_count":null,"outputs":[]}]}